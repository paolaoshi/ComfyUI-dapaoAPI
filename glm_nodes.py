"""
å¤§ç‚® API - æ™ºè°± AI (GLM) èŠ‚ç‚¹é›†åˆ
æä¾›å›¾åƒåæ¨å’Œæç¤ºè¯æ¶¦è‰²åŠŸèƒ½
åŸºäºæ™ºè°± API å®ç°

ä½œè€…ï¼š@ç‚®è€å¸ˆçš„å°è¯¾å ‚
ç‰ˆæœ¬ï¼šv2.1.0
"""

import os
import json
import base64
import random
import io
from PIL import Image
import numpy as np
import torch

# å°è¯•å¯¼å…¥æ™ºè°±AI SDK
try:
    from zhipuai import ZhipuAI
    ZHIPUAI_AVAILABLE = True
except ImportError:
    ZHIPUAI_AVAILABLE = False
    print("[GLM_Nodes] è­¦å‘Šï¼šæœªå®‰è£… zhipuaiï¼Œè¯·è¿è¡Œ: pip install zhipuai")

# è·å–å½“å‰ç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
GLM_CONFIG_FILE = os.path.join(CURRENT_DIR, 'glm_config.json')
GLM_TEMPLATES_DIR = os.path.join(CURRENT_DIR, 'glm_optimization_templates')

# ç»Ÿä¸€èŠ‚ç‚¹é¢œè‰² (æ©™æ£•è‰²)
NODE_COLOR = "#773508"  # RGB(119, 53, 8)


# ==================== è¾…åŠ©å‡½æ•° ====================

def _log_info(message):
    """ç»Ÿä¸€çš„æ—¥å¿—è¾“å‡ºå‡½æ•°"""
    print(f"[dapaoAPI-GLM] ä¿¡æ¯ï¼š{message}")


def _log_warning(message):
    """ç»Ÿä¸€çš„è­¦å‘Šè¾“å‡ºå‡½æ•°"""
    print(f"[dapaoAPI-GLM] è­¦å‘Šï¼š{message}")


def _log_error(message):
    """ç»Ÿä¸€çš„é”™è¯¯è¾“å‡ºå‡½æ•°"""
    print(f"[dapaoAPI-GLM] é”™è¯¯ï¼š{message}")


def get_glm_config():
    """
    è¯»å– GLM é…ç½®æ–‡ä»¶
    
    Returns:
        dict: é…ç½®å­—å…¸
    """
    default_config = {
        "ZHIPUAI_API_KEY": "",
        "default_model": "GLM-4.5-Flash",
        "default_vision_model": "glm-4v-flash",
        "temperature": 0.9,
        "top_p": 0.7,
        "max_tokens": 2048
    }
    
    try:
        if os.path.exists(GLM_CONFIG_FILE):
            with open(GLM_CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return {**default_config, **config}
        else:
            return default_config
    except Exception as e:
        _log_error(f"è¯»å– GLM é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return default_config


def get_zhipuai_api_key():
    """
    è·å–æ™ºè°± API Key
    ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶
    
    Returns:
        str: API Key
    """
    # 1. å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    env_api_key = os.getenv("ZHIPUAI_API_KEY")
    if env_api_key:
        _log_info("ä½¿ç”¨ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEY")
        return env_api_key
    
    # 2. ä»é…ç½®æ–‡ä»¶è·å–
    config = get_glm_config()
    api_key = config.get("ZHIPUAI_API_KEY", "")
    if api_key and api_key != "YOUR_ZHIPUAI_API_KEY_HERE":
        _log_info("ä»é…ç½®æ–‡ä»¶è¯»å– API Key")
        return api_key
    
    _log_warning("æœªæ‰¾åˆ° API Keyï¼Œè¯·åœ¨ glm_config.json ä¸­é…ç½®")
    return ""


def tensor_to_base64(image_tensor: torch.Tensor) -> str:
    """
    å°† ComfyUI å›¾åƒå¼ é‡è½¬æ¢ä¸º base64 ç¼–ç 
    
    Args:
        image_tensor: ComfyUI å›¾åƒå¼ é‡ [B, H, W, C], å€¼èŒƒå›´ [0, 1]
        
    Returns:
        str: base64 ç¼–ç çš„å›¾åƒæ•°æ®ï¼ˆå¸¦ data URL å‰ç¼€ï¼‰
    """
    try:
        # ComfyUI çš„ IMAGE æ˜¯ PyTorch å¼ é‡ï¼ŒèŒƒå›´ [0,1]ï¼Œå½¢çŠ¶ [B, H, W, C]
        # è½¬æ¢ä¸º PIL Imageï¼ŒèŒƒå›´ [0,255]
        i = 255. * image_tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8)[0])  # å–ç¬¬ä¸€ä¸ª batch
        
        # è½¬æ¢ä¸º base64
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        
        return f"data:image/png;base64,{image_base64}"
    except Exception as e:
        _log_error(f"å›¾åƒè½¬ base64 å¤±è´¥: {e}")
        return None


def get_glm_optimization_templates():
    """
    è·å– GLM ä¼˜åŒ–æ¨¡æ¿åˆ—è¡¨
    ä» glm_optimization_templates æ–‡ä»¶å¤¹è¯»å–æ‰€æœ‰ .txt æ–‡ä»¶
    
    Returns:
        list: æ¨¡æ¿åç§°åˆ—è¡¨ï¼ˆä¸å«æ‰©å±•åï¼‰
    """
    templates = []  # ä¸å†åŒ…å«"è‡ªå®šä¹‰è¾“å…¥"é€‰é¡¹
    
    try:
        if os.path.exists(GLM_TEMPLATES_DIR):
            # è¯»å–æ‰€æœ‰ .txt æ–‡ä»¶
            for filename in sorted(os.listdir(GLM_TEMPLATES_DIR)):
                if filename.endswith('.txt'):
                    # å»æ‰ .txt æ‰©å±•å
                    template_name = filename[:-4]
                    templates.append(template_name)
            
            if len(templates) > 0:
                _log_info(f"åŠ è½½äº† {len(templates)} ä¸ª GLM ä¼˜åŒ–æ¨¡æ¿")
        else:
            _log_warning(f"GLM æ¨¡æ¿æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {GLM_TEMPLATES_DIR}")
            templates.extend(["å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™", "å³æ¢¦å¤šå›¾ç¼–è¾‘", "wan2.2è§†é¢‘æ‰©å†™"])
    except Exception as e:
        _log_error(f"è¯»å– GLM ä¼˜åŒ–æ¨¡æ¿å¤±è´¥: {e}")
        templates.extend(["å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™", "å³æ¢¦å¤šå›¾ç¼–è¾‘", "wan2.2è§†é¢‘æ‰©å†™"])
    
    # ç¡®ä¿é»˜è®¤æ¨¡æ¿åœ¨ç¬¬ä¸€ä½
    if "å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™" in templates:
        templates.remove("å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™")
        templates.insert(0, "å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™")
    
    return templates if templates else ["å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™"]


def load_glm_template_content(template_name: str) -> str:
    """
    åŠ è½½æŒ‡å®š GLM ä¼˜åŒ–æ¨¡æ¿çš„å†…å®¹
    
    Args:
        template_name: æ¨¡æ¿åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
        
    Returns:
        str: æ¨¡æ¿å†…å®¹
    """
    template_file = os.path.join(GLM_TEMPLATES_DIR, f"{template_name}.txt")
    
    try:
        if not os.path.exists(template_file):
            _log_warning(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_file}")
            return ""
        
        with open(template_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾åˆ†éš”çº¿
        marker = "==================== ä¼˜åŒ–æ–¹æ¡ˆå†…å®¹ ===================="
        if marker in content:
            # æå–åˆ†éš”çº¿åçš„å†…å®¹
            parts = content.split(marker)
            if len(parts) >= 2:
                template_content = parts[1].strip()
                return template_content
        
        # å¦‚æœæ²¡æœ‰åˆ†éš”çº¿ï¼Œè¿‡æ»¤æ‰æ³¨é‡Šè¡Œ
        lines = []
        for line in content.split('\n'):
            stripped = line.strip()
            if stripped and not stripped.startswith('#'):
                lines.append(line)
        
        return '\n'.join(lines)
    
    except Exception as e:
        _log_error(f"è¯»å–æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
        return ""


# ==================== èŠ‚ç‚¹ç±» ====================

class GLM_ImageToPrompt:
    """
    æ™ºè°± AI å›¾åƒåæ¨èŠ‚ç‚¹ v3.1
    
    ä½¿ç”¨ GLM-4V è§†è§‰æ¨¡å‹åˆ†æå›¾åƒï¼Œç”Ÿæˆè¯¦ç»†çš„å›¾åƒæè¿°
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - ğŸ–¼ï¸ å¤šå›¾æ”¯æŒï¼šæœ€å¤šæ”¯æŒ4å¼ å›¾ç‰‡åŒæ—¶åˆ†æ
    - ğŸ“ è‡ªå®šä¹‰åæ¨æŒ‡ä»¤ï¼šçµæ´»æ§åˆ¶è¾“å‡ºé£æ ¼
    - ğŸ² ç§å­æ§åˆ¶ï¼šæ”¯æŒå›ºå®šã€éšæœºã€é€’å¢ä¸‰ç§æ¨¡å¼
    
    é€‚ç”¨åœºæ™¯ï¼š
    - å›¾ç”Ÿå›¾å‰çš„æç¤ºè¯å‚è€ƒ
    - äº†è§£å›¾åƒå†…å®¹
    - ç”Ÿæˆè®­ç»ƒæ•°æ®æ ‡æ³¨
    - å¤šå›¾å¯¹æ¯”åˆ†æ
    
    ä½œè€…ï¼š@ç‚®è€å¸ˆçš„å°è¯¾å ‚
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        config = get_glm_config()
        
        return {
            "required": {
                # === å›¾åƒè¾“å…¥ ===
                "ğŸ–¼ï¸ å›¾åƒ1": ("IMAGE", {
                    "tooltip": "å¿…å¡«ï¼šä¸»è¦åˆ†æå›¾åƒ"
                }),
                
                # === åæ¨æŒ‡ä»¤ ===
                "ğŸ“ åæ¨æŒ‡ä»¤": ("STRING", {
                    "multiline": True,
                    "default": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æä¸“å®¶ï¼Œèƒ½å¤Ÿå°†å›¾ç‰‡å†…å®¹è½¬åŒ–ä¸ºé«˜è´¨é‡çš„è‹±æ–‡æç¤ºè¯ã€‚

è¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡ï¼Œç”Ÿæˆè¯¦ç»†çš„è‹±æ–‡æè¿°ï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»ä½“ï¼šäººç‰©/ç‰©ä½“çš„å¤–è§‚ã€ç‰¹å¾ã€è¡¨æƒ…ã€åŠ¨ä½œ
2. åœºæ™¯ï¼šç¯å¢ƒã€èƒŒæ™¯ã€æ—¶é—´ã€å¤©æ°”ã€å…‰çº¿
3. æ„å›¾ï¼šè§†è§’ã€æ™¯åˆ«ã€ç©ºé—´å…³ç³»
4. é£æ ¼ï¼šè‰ºæœ¯é£æ ¼ã€è‰²å½©ã€æ°›å›´ã€è´¨æ„Ÿ
5. ç»†èŠ‚ï¼šçº¹ç†ã€æè´¨ã€è£…é¥°ã€é“å…·ç­‰

è¦æ±‚ï¼š
- ä½¿ç”¨è‹±æ–‡
- è¯¦ç»†å…·ä½“
- ç”¨é€—å·è¿æ¥ä¸åŒæè¿°
- æœ«å°¾æ·»åŠ ç”»è´¨è¯ï¼šhigh quality, ultra detailed, masterpiece

åªè¾“å‡ºæœ€ç»ˆçš„è‹±æ–‡æç¤ºè¯ï¼Œä¸è¦åŒ…å«è§£é‡Šã€‚""",
                    "placeholder": "æè¿°å¦‚ä½•åˆ†æå›¾åƒ..."
                }),
                
                # === API é…ç½® ===
                "ğŸ”‘ APIå¯†é’¥": ("STRING", {
                    "default": "",
                    "placeholder": "ç•™ç©ºåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–"
                }),
                "ğŸ¤– è§†è§‰æ¨¡å‹": ("STRING", {
                    "default": config.get("default_vision_model", "glm-4v-flash"),
                    "placeholder": "å¦‚: glm-4v-flash, glm-4v-plus"
                }),
                
                # === é«˜çº§è®¾ç½® ===
                "ğŸ² éšæœºç§å­": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 0xffffffffffffffff,
                    "tooltip": "éšæœºç§å­å€¼"
                }),
                
                "ğŸ›ï¸ ç§å­æ§åˆ¶": (["å›ºå®š", "éšæœº", "é€’å¢"], {
                    "default": "éšæœº",
                    "tooltip": "å›ºå®š: ä½¿ç”¨ä¸Šæ–¹ç§å­å€¼; éšæœº: æ¯æ¬¡ç”Ÿæˆæ–°ç§å­; é€’å¢: ç§å­å€¼+1"
                }),
            },
            "optional": {
                # === å¯é€‰å›¾åƒè¾“å…¥ ===
                "ğŸ–¼ï¸ å›¾åƒ2": ("IMAGE", {
                    "tooltip": "å¯é€‰ï¼šé¢å¤–çš„å¯¹æ¯”å›¾åƒ"
                }),
                "ğŸ–¼ï¸ å›¾åƒ3": ("IMAGE", {
                    "tooltip": "å¯é€‰ï¼šé¢å¤–çš„å¯¹æ¯”å›¾åƒ"
                }),
                "ğŸ–¼ï¸ å›¾åƒ4": ("IMAGE", {
                    "tooltip": "å¯é€‰ï¼šé¢å¤–çš„å¯¹æ¯”å›¾åƒ"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("ğŸ¨ å›¾åƒæè¿°", "â„¹ï¸ å¤„ç†ä¿¡æ¯")
    FUNCTION = "analyze_image"
    CATEGORY = "ğŸ¤–dapaoAPI"
    DESCRIPTION = "ä½¿ç”¨æ™ºè°± AI åˆ†æå›¾åƒï¼Œæ”¯æŒå¤šå›¾è¾“å…¥ã€ç”Ÿæˆè¯¦ç»†çš„è‹±æ–‡æç¤ºè¯ | ä½œè€…: @ç‚®è€å¸ˆçš„å°è¯¾å ‚"
    OUTPUT_NODE = False
    
    def __init__(self):
        # è®¾ç½®èŠ‚ç‚¹é¢œè‰²
        self.color = NODE_COLOR
        self.bgcolor = NODE_COLOR
        # ä¿å­˜ä¸Šä¸€æ¬¡ä½¿ç”¨çš„ç§å­ï¼ˆç”¨äºé€’å¢æ¨¡å¼ï¼‰
        self.last_seed = 0
    
    def analyze_image(self, **kwargs):
        """åˆ†æå›¾åƒï¼Œç”Ÿæˆæç¤ºè¯ï¼ˆæ”¯æŒå¤šå›¾ï¼‰"""
        
        # æ£€æŸ¥ SDK æ˜¯å¦å¯ç”¨
        if not ZHIPUAI_AVAILABLE:
            error_msg = "âŒ é”™è¯¯ï¼šæœªå®‰è£… zhipuai SDK\n\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\npip install zhipuai\n\nå®‰è£…åé‡å¯ ComfyUI"
            _log_error(error_msg)
            return ("", error_msg)
        
        # å‚æ•°è§£æ
        image1 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ1")
        image2 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ2")
        image3 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ3")
        image4 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ4")
        prompt_text = kwargs.get("ğŸ“ åæ¨æŒ‡ä»¤", "")
        api_key = kwargs.get("ğŸ”‘ APIå¯†é’¥", "")
        model_name = kwargs.get("ğŸ¤– è§†è§‰æ¨¡å‹", "glm-4v-flash")
        seed = kwargs.get("ğŸ² éšæœºç§å­", 0)
        seed_control = kwargs.get("ğŸ›ï¸ ç§å­æ§åˆ¶", "éšæœº")
        
        # è·å– API Key
        final_api_key = api_key.strip() or get_zhipuai_api_key()
        if not final_api_key:
            error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾› API Key\n\nè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œä¹‹ä¸€ï¼š\n1. åœ¨èŠ‚ç‚¹çš„ã€ğŸ”‘ APIå¯†é’¥ã€‘å‚æ•°ä¸­è¾“å…¥\n2. ç¼–è¾‘ glm_config.json æ–‡ä»¶é…ç½®\n3. è®¾ç½®ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEY"
            _log_error(error_msg)
            return ("", error_msg)
        
        # æ£€æŸ¥å›¾åƒè¾“å…¥ï¼ˆè‡³å°‘éœ€è¦å›¾åƒ1ï¼‰
        if image1 is None:
            error_msg = "âŒ é”™è¯¯ï¼šè¯·æä¾›è‡³å°‘ä¸€å¼ å›¾åƒ\n\nè¯·åœ¨ã€ğŸ–¼ï¸ å›¾åƒ1ã€‘å‚æ•°ä¸­ä¸Šä¼ å›¾åƒ"
            _log_error(error_msg)
            return ("", error_msg)
        
        try:
            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„å›¾åƒ
            images = []
            if image1 is not None:
                images.append(("å›¾åƒ1", image1))
            if image2 is not None:
                images.append(("å›¾åƒ2", image2))
            if image3 is not None:
                images.append(("å›¾åƒ3", image3))
            if image4 is not None:
                images.append(("å›¾åƒ4", image4))
            
            _log_info(f"å…±æ¥æ”¶åˆ° {len(images)} å¼ å›¾åƒ")
            
            # è½¬æ¢æ‰€æœ‰å›¾åƒä¸º base64
            image_base64_list = []
            for img_name, img_tensor in images:
                _log_info(f"æ­£åœ¨è½¬æ¢ {img_name}...")
                img_base64 = tensor_to_base64(img_tensor)
                if not img_base64:
                    _log_warning(f"{img_name} è½¬æ¢å¤±è´¥ï¼Œå·²è·³è¿‡")
                    continue
                image_base64_list.append((img_name, img_base64))
            
            if not image_base64_list:
                error_msg = "âŒ é”™è¯¯ï¼šæ‰€æœ‰å›¾åƒè½¬æ¢å¤±è´¥"
                _log_error(error_msg)
                return ("", error_msg)
            
            _log_info(f"æˆåŠŸè½¬æ¢ {len(image_base64_list)} å¼ å›¾åƒ")
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            _log_info("åˆå§‹åŒ–æ™ºè°± AI å®¢æˆ·ç«¯...")
            client = ZhipuAI(api_key=final_api_key)
            
            # æ„å»ºè¯·æ±‚å†…å®¹ï¼ˆå…ˆæ·»åŠ æ–‡æœ¬æŒ‡ä»¤ï¼‰
            content_parts = [{"type": "text", "text": prompt_text}]
            
            # æ·»åŠ æ‰€æœ‰å›¾åƒ
            for img_name, img_base64 in image_base64_list:
                content_parts.append({
                    "type": "image_url",
                    "image_url": {"url": img_base64}
                })
            
            # === ç§å­å¤„ç† ===
            import random
            
            # æ ¹æ®ç§å­æ§åˆ¶æ¨¡å¼å†³å®šæœ€ç»ˆç§å­å€¼
            if seed_control == "å›ºå®š":
                effective_seed = seed
                seed_mode = "å›ºå®š"
            elif seed_control == "éšæœº":
                effective_seed = random.randint(0, 0xffffffffffffffff)
                seed_mode = "éšæœº"
            elif seed_control == "é€’å¢":
                if self.last_seed == 0:
                    effective_seed = seed if seed != 0 else random.randint(0, 0xffffffffffffffff)
                else:
                    effective_seed = self.last_seed + 1
                seed_mode = "é€’å¢"
            else:
                effective_seed = random.randint(0, 0xffffffffffffffff)
                seed_mode = "éšæœº"
            
            # ä¿å­˜å½“å‰ç§å­ä¾›ä¸‹æ¬¡ä½¿ç”¨
            self.last_seed = effective_seed
            random.seed(effective_seed)
            
            _log_info(f"è°ƒç”¨ GLM-4V ({model_name}) åˆ†æ {len(image_base64_list)} å¼ å›¾åƒ...")
            _log_info(f"ä½¿ç”¨ç§å­ï¼š{effective_seed}ï¼Œæ¨¡å¼ï¼š{seed_mode}")
            
            # æ™ºè°±APIçš„ç§å­å€¼èŒƒå›´é™åˆ¶ï¼šå¿…é¡»åœ¨ 2147483647 ä»¥å†…
            # å°†å¤§ç§å­å€¼æ˜ å°„åˆ°æ™ºè°±APIæ”¯æŒçš„èŒƒå›´å†… (1 - 2147483647)
            zhipu_seed = (effective_seed % 2147483647) + 1 if effective_seed > 2147483647 else effective_seed
            if zhipu_seed != effective_seed:
                _log_info(f"ç§å­å€¼è½¬æ¢: {effective_seed} -> {zhipu_seed} (æ™ºè°±APIé™åˆ¶)")
            
            # è°ƒç”¨ API
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": content_parts}],
                seed=zhipu_seed if zhipu_seed != 0 else None
            )
            
            result_text = str(response.choices[0].message.content)
            _log_info("âœ… å›¾åƒåˆ†ææˆåŠŸ")
            
            # æ„å»ºè¯¦ç»†çš„ä¿¡æ¯è¾“å‡º
            info_lines = [
                "ğŸ‰ GLM å›¾åƒåˆ†ææˆåŠŸ",
                "",
                "ğŸ“Š åˆ†æä¿¡æ¯ï¼š",
                f"   æ¨¡å‹ï¼š{model_name}",
                f"   å›¾åƒæ•°é‡ï¼š{len(image_base64_list)} å¼ ",
                f"   å›¾åƒåˆ—è¡¨ï¼š{', '.join([name for name, _ in image_base64_list])}",
                "",
                "ğŸ² ç§å­ä¿¡æ¯ï¼š",
                f"   ç§å­å€¼ï¼š{effective_seed}",
                f"   æ§åˆ¶æ¨¡å¼ï¼š{seed_mode}",
                "",
                "âœ… åˆ†æå®Œæˆ"
            ]
            
            info = "\n".join(info_lines)
            
            return (result_text, info)
            
        except Exception as e:
            error_msg = f"âŒ é”™è¯¯ï¼šå›¾åƒåˆ†æå¤±è´¥\n\né”™è¯¯è¯¦æƒ…ï¼š{str(e)}\n\nå»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®\n3. æŸ¥çœ‹ç»ˆç«¯å®Œæ•´æ—¥å¿—"
            _log_error(error_msg)
            import traceback
            _log_error(traceback.format_exc())
            return ("", error_msg)


class GLM_PromptPolish:
    """
    æ™ºè°± AI æç¤ºè¯æ¶¦è‰²èŠ‚ç‚¹ v3.1
    
    ä½¿ç”¨ GLM-4 å¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–ã€æ‰©å†™ã€æ¶¦è‰²æç¤ºè¯
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - ğŸ“ å†…ç½®æç¤ºè¯è¾“å…¥ï¼šç›´æ¥åœ¨èŠ‚ç‚¹å†…è¾“å…¥åŸå§‹æç¤ºè¯
    - âœ¨ é¢„è®¾ä¼˜åŒ–æ–¹æ¡ˆï¼šwan2.2è§†é¢‘æ‰©å†™ã€å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™ã€å³æ¢¦å¤šå›¾ç¼–è¾‘
    - ğŸ¯ ç³»ç»Ÿæç¤ºè¯ä¼˜å…ˆçº§ï¼šè‡ªå®šä¹‰è¾“å…¥ > é¢„è®¾æ–¹æ¡ˆï¼ˆé»˜è®¤"å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™"ï¼‰
    - ğŸ“ æ™ºèƒ½é•¿åº¦æ§åˆ¶ï¼šè‡ªåŠ¨ä¼˜åŒ–åˆ°æŒ‡å®š token é•¿åº¦
    - ğŸ’¡ è¯¦ç»†é”™è¯¯æç¤ºï¼šæ¸…æ™°çš„çŠ¶æ€å’Œé”™è¯¯å¼•å¯¼
    - ğŸ¨ ç¾åŒ–å¸ƒå±€ï¼šå‚è€ƒ Seedream å¤šå›¾ç¼–è¾‘èŠ‚ç‚¹é£æ ¼
    
    ä½œè€…ï¼š@ç‚®è€å¸ˆçš„å°è¯¾å ‚
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        config = get_glm_config()
        templates = get_glm_optimization_templates()
        
        return {
            "required": {
                # === è¾“å…¥æç¤ºè¯ ===
                "ğŸ“ åŸå§‹æç¤ºè¯": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "è¾“å…¥éœ€è¦ä¼˜åŒ–çš„æç¤ºè¯..."
                }),
                
                # === ä¼˜åŒ–æ–¹æ¡ˆé€‰æ‹© ===
                "âœ¨ ä¼˜åŒ–æ–¹æ¡ˆ": (templates, {
                    "default": templates[0] if templates else "å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™",
                    "tooltip": "é€‰æ‹©é¢„è®¾çš„ä¼˜åŒ–æ–¹æ¡ˆï¼ˆç•™ç©ºç³»ç»Ÿæç¤ºè¯åˆ™ä½¿ç”¨æ­¤é¢„è®¾ï¼‰"
                }),
                
                # === ç³»ç»Ÿæç¤ºè¯ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰===
                "ğŸ¯ ç³»ç»Ÿæç¤ºè¯": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "ï¼ˆå¯é€‰ï¼‰è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Œç•™ç©ºåˆ™ä½¿ç”¨ä¸Šæ–¹é¢„è®¾\næ”¯æŒ {prompt} å ä½ç¬¦"
                }),
                
                # === API é…ç½® ===
                "ğŸ”‘ APIå¯†é’¥": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "ç•™ç©ºåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–"
                }),
                
                "ğŸ¤– æ¨¡å‹åç§°": ("STRING", {
                    "default": config.get("default_model", "GLM-4.5-Flash"),
                    "multiline": False,
                    "placeholder": "å¦‚: GLM-4.5-Flash, GLM-4-Plus"
                }),
                
                # === é«˜çº§å‚æ•° ===
                "ğŸŒ¡ï¸ æ¸©åº¦": ("FLOAT", {
                    "default": config.get("temperature", 0.9),
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "tooltip": "æ¸©åº¦å‚æ•°ï¼Œè¶Šé«˜è¶Šæœ‰åˆ›é€ æ€§"
                }),
                
                "ğŸ² Top-P": ("FLOAT", {
                    "default": config.get("top_p", 0.7),
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "tooltip": "Top-P é‡‡æ ·å‚æ•°"
                }),
                
                "ğŸ“ æœ€å¤§é•¿åº¦": ("INT", {
                    "default": config.get("max_tokens", 2048),
                    "min": 256,
                    "max": 4096,
                    "step": 256,
                    "tooltip": "æœ€å¤§ç”Ÿæˆ token æ•°é‡"
                }),
                
                "ğŸ² éšæœºç§å­": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 0xffffffffffffffff,
                    "tooltip": "éšæœºç§å­å€¼"
                }),
                
                "ğŸ›ï¸ ç§å­æ§åˆ¶": (["å›ºå®š", "éšæœº", "é€’å¢"], {
                    "default": "éšæœº",
                    "tooltip": "å›ºå®š: ä½¿ç”¨ä¸Šæ–¹ç§å­å€¼; éšæœº: æ¯æ¬¡ç”Ÿæˆæ–°ç§å­; é€’å¢: ç§å­å€¼+1"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("âœ¨ ä¼˜åŒ–åæç¤ºè¯", "ğŸ“ åŸå§‹æç¤ºè¯", "â„¹ï¸ å¤„ç†ä¿¡æ¯")
    FUNCTION = "polish_prompt"
    CATEGORY = "ğŸ¤–dapaoAPI"
    DESCRIPTION = "ä½¿ç”¨æ™ºè°± AI ä¼˜åŒ–å’Œæ¶¦è‰²æç¤ºè¯ï¼Œæ”¯æŒæ¨¡æ¿é€‰æ‹©ã€æ™ºèƒ½é•¿åº¦æ§åˆ¶ã€3ç§ç§å­æ¨¡å¼ã€è¯¦ç»†é”™è¯¯æç¤º | ä½œè€…: @ç‚®è€å¸ˆçš„å°è¯¾å ‚"
    OUTPUT_NODE = False
    
    def __init__(self):
        # è®¾ç½®èŠ‚ç‚¹é¢œè‰²
        self.color = NODE_COLOR
        self.bgcolor = NODE_COLOR
        # ä¿å­˜ä¸Šä¸€æ¬¡ä½¿ç”¨çš„ç§å­ï¼ˆç”¨äºé€’å¢æ¨¡å¼ï¼‰
        self.last_seed = 0
    
    def polish_prompt(self, **kwargs):
        """æ¶¦è‰²æç¤ºè¯"""
        
        # å‚æ•°è§£æ
        original_prompt = kwargs.get("ğŸ“ åŸå§‹æç¤ºè¯", "")
        optimization_preset = kwargs.get("âœ¨ ä¼˜åŒ–æ–¹æ¡ˆ", "å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™")
        custom_system_prompt = kwargs.get("ğŸ¯ ç³»ç»Ÿæç¤ºè¯", "")
        api_key = kwargs.get("ğŸ”‘ APIå¯†é’¥", "")
        model_name = kwargs.get("ğŸ¤– æ¨¡å‹åç§°", "GLM-4.5-Flash")
        temperature = kwargs.get("ğŸŒ¡ï¸ æ¸©åº¦", 0.9)
        top_p = kwargs.get("ğŸ² Top-P", 0.7)
        max_tokens = kwargs.get("ğŸ“ æœ€å¤§é•¿åº¦", 2048)
        seed = kwargs.get("ğŸ² éšæœºç§å­", 0)
        seed_control = kwargs.get("ğŸ›ï¸ ç§å­æ§åˆ¶", "éšæœº")
        
        # çŠ¶æ€ä¿¡æ¯æ”¶é›†å™¨
        status_info = []
        
        # æ£€æŸ¥ SDK æ˜¯å¦å¯ç”¨
        if not ZHIPUAI_AVAILABLE:
            error_msg = "âŒ é”™è¯¯ï¼šæœªå®‰è£… zhipuai SDK\n\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\npip install zhipuai\n\nå®‰è£…åé‡å¯ ComfyUI"
            _log_error(error_msg)
            status_info.append("âŒ SDK æœªå®‰è£…")
            return ("", "", error_msg)
        
        # è·å– API Key
        final_api_key = api_key.strip() or get_zhipuai_api_key()
        if not final_api_key:
            error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾› API Key\n\nè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œä¹‹ä¸€ï¼š\n1. åœ¨èŠ‚ç‚¹çš„ã€api_keyã€‘å‚æ•°ä¸­è¾“å…¥\n2. ç¼–è¾‘ glm_config.json æ–‡ä»¶é…ç½®\n3. è®¾ç½®ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEY"
            _log_error(error_msg)
            status_info.append("âŒ API Key ç¼ºå¤±")
            return ("", original_prompt, error_msg)
        
        status_info.append("âœ… API Key å·²é…ç½®")
        
        # æ£€æŸ¥è¾“å…¥
        if not original_prompt or not original_prompt.strip():
            error_msg = "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥éœ€è¦ä¼˜åŒ–çš„æç¤ºè¯\n\nè¯·åœ¨ã€ğŸ“ åŸå§‹æç¤ºè¯ã€‘å‚æ•°ä¸­è¾“å…¥å†…å®¹"
            _log_warning(error_msg)
            status_info.append("âŒ è¾“å…¥ä¸ºç©º")
            return ("", "", error_msg)
        
        try:
            # === ä¼˜å…ˆçº§æ§åˆ¶ï¼šè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ > é¢„è®¾æ–¹æ¡ˆ ===
            final_optimization_prompt = ""
            used_method = ""
            
            if custom_system_prompt and custom_system_prompt.strip():
                # æœ€é«˜ä¼˜å…ˆçº§ï¼šç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ç³»ç»Ÿæç¤ºè¯
                final_optimization_prompt = custom_system_prompt.strip()
                used_method = "è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯"
                _log_info("âœ… ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯")
                status_info.append("ğŸ“ ä½¿ç”¨ï¼šè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯")
            else:
                # ä½¿ç”¨é¢„è®¾æ–¹æ¡ˆï¼ˆé»˜è®¤"å³æ¢¦æ–‡ç”Ÿå›¾æ‰©å†™"ï¼‰
                template_content = load_glm_template_content(optimization_preset)
                if template_content:
                    final_optimization_prompt = template_content
                    used_method = f"é¢„è®¾ï¼š{optimization_preset}"
                    _log_info(f"âœ… ä½¿ç”¨é¢„è®¾æ¨¡æ¿: {optimization_preset}")
                    status_info.append(f"ğŸ“ ä½¿ç”¨ï¼š{optimization_preset}")
                else:
                    _log_warning(f"é¢„è®¾ '{optimization_preset}' åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤")
                    final_optimization_prompt = "è¯·å°†ä»¥ä¸‹å†…å®¹ä¼˜åŒ–ä¸ºè¯¦ç»†çš„æç¤ºè¯ï¼š{prompt}"
                    used_method = "é»˜è®¤æ–¹æ¡ˆï¼ˆé¢„è®¾åŠ è½½å¤±è´¥ï¼‰"
                    status_info.append("âš ï¸ é¢„è®¾åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤")
            
            # æ›¿æ¢å ä½ç¬¦
            final_optimization_prompt = final_optimization_prompt.replace("{prompt}", original_prompt)
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            _log_info("åˆå§‹åŒ–æ™ºè°± AI å®¢æˆ·ç«¯...")
            status_info.append("ğŸ”„ æ­£åœ¨è¿æ¥æ™ºè°± API...")
            
            try:
                client = ZhipuAI(api_key=final_api_key)
                status_info.append("âœ… API è¿æ¥æˆåŠŸ")
            except Exception as init_error:
                error_msg = f"âŒ é”™è¯¯ï¼šAPI åˆå§‹åŒ–å¤±è´¥\n\né”™è¯¯è¯¦æƒ…ï¼š{str(init_error)}\n\nå¯èƒ½åŸå› ï¼š\n1. API Key æ— æ•ˆ\n2. ç½‘ç»œè¿æ¥é—®é¢˜\n3. SDK ç‰ˆæœ¬é—®é¢˜\n\nå»ºè®®ï¼šæ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®"
                _log_error(error_msg)
                status_info.append("âŒ API è¿æ¥å¤±è´¥")
                return ("", original_prompt, "\n".join(status_info) + "\n\n" + error_msg)
            
            # === ç§å­å¤„ç† ===
            import random
            
            # æ ¹æ®ç§å­æ§åˆ¶æ¨¡å¼å†³å®šæœ€ç»ˆç§å­å€¼
            if seed_control == "å›ºå®š":
                # å›ºå®šæ¨¡å¼ï¼šä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ç§å­å€¼
                effective_seed = seed
                seed_mode = "å›ºå®š"
            elif seed_control == "éšæœº":
                # éšæœºæ¨¡å¼ï¼šæ¯æ¬¡ç”Ÿæˆæ–°çš„éšæœºç§å­
                effective_seed = random.randint(0, 0xffffffffffffffff)
                seed_mode = "éšæœº"
            elif seed_control == "é€’å¢":
                # é€’å¢æ¨¡å¼ï¼šåœ¨ä¸Šä¸€æ¬¡ç§å­åŸºç¡€ä¸Š+1
                if self.last_seed == 0:
                    effective_seed = seed if seed != 0 else random.randint(0, 0xffffffffffffffff)
                else:
                    effective_seed = self.last_seed + 1
                seed_mode = "é€’å¢"
            else:
                # é»˜è®¤ï¼šéšæœº
                effective_seed = random.randint(0, 0xffffffffffffffff)
                seed_mode = "éšæœº"
            
            # ä¿å­˜å½“å‰ç§å­ä¾›ä¸‹æ¬¡ä½¿ç”¨
            self.last_seed = effective_seed
            
            random.seed(effective_seed)
            seed_info = f"ğŸ² ç§å­ï¼š{effective_seed} (æ¨¡å¼: {seed_mode})"
            status_info.append(seed_info)
            _log_info(f"ä½¿ç”¨ç§å­ï¼š{effective_seed}ï¼Œæ¨¡å¼ï¼š{seed_mode}")
            
            # æ™ºè°±APIçš„ç§å­å€¼èŒƒå›´é™åˆ¶ï¼šå¿…é¡»åœ¨ 2147483647 ä»¥å†…
            # å°†å¤§ç§å­å€¼æ˜ å°„åˆ°æ™ºè°±APIæ”¯æŒçš„èŒƒå›´å†… (1 - 2147483647)
            zhipu_seed = (effective_seed % 2147483647) + 1 if effective_seed > 2147483647 else effective_seed
            if zhipu_seed != effective_seed:
                _log_info(f"ç§å­å€¼è½¬æ¢: {effective_seed} -> {zhipu_seed} (æ™ºè°±APIé™åˆ¶)")
            
            _log_info(f"è°ƒç”¨ GLM-4 ({model_name}) ä¼˜åŒ–æç¤ºè¯...")
            _log_info(f"åŸå§‹æç¤ºè¯: {original_prompt[:50]}...")
            _log_info(f"æœ€å¤§ç”Ÿæˆé•¿åº¦: {max_tokens} tokens")
            
            status_info.append(f"ğŸ¤– æ¨¡å‹ï¼š{model_name}")
            status_info.append(f"ğŸ“ æœ€å¤§é•¿åº¦ï¼š{max_tokens} tokens")
            status_info.append("ğŸ”„ æ­£åœ¨ä¼˜åŒ–æç¤ºè¯...")
            
            # === è°ƒç”¨ API ç”Ÿæˆä¼˜åŒ–åçš„æç¤ºè¯ ===
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æç¤ºè¯ä¼˜åŒ–ä¸“å®¶ã€‚"},
                {"role": "user", "content": final_optimization_prompt}
            ]
            
            try:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=temperature,
                    top_p=top_p,
                    max_tokens=max_tokens,
                    seed=zhipu_seed if zhipu_seed != 0 else None,
                )
            except Exception as api_error:
                error_msg = f"âŒ é”™è¯¯ï¼šAPI è°ƒç”¨å¤±è´¥\n\né”™è¯¯è¯¦æƒ…ï¼š{str(api_error)}\n\nå¯èƒ½åŸå› ï¼š\n1. API Key å·²å¤±æ•ˆæˆ–é¢åº¦ä¸è¶³\n2. ç½‘ç»œè¿æ¥ä¸­æ–­\n3. æ¨¡å‹åç§°é”™è¯¯\n4. è¯·æ±‚è¶…æ—¶\n\nå»ºè®®ï¼š\n1. æ£€æŸ¥æ™ºè°± AI æ§åˆ¶å°ä½™é¢\n2. æ£€æŸ¥ç½‘ç»œè¿æ¥\n3. å°è¯•é‡æ–°è¿è¡Œ"
                _log_error(error_msg)
                status_info.append("âŒ API è°ƒç”¨å¤±è´¥")
                return ("", original_prompt, "\n".join(status_info) + "\n\n" + error_msg)
            
            optimized_prompt = response.choices[0].message.content
            status_info.append("âœ… ä¼˜åŒ–å®Œæˆ")
            
            _log_info("æç¤ºè¯ä¼˜åŒ–æˆåŠŸ")
            _log_info(f"ä¼˜åŒ–åæç¤ºè¯: {optimized_prompt[:100]}...")
            
            # é•¿åº¦ç»Ÿè®¡
            final_word_count = len(optimized_prompt.split())
            final_estimated_tokens = int(final_word_count * 1.3)
            
            status_info.append("=" * 40)
            status_info.append("âœ… ä¼˜åŒ–æˆåŠŸå®Œæˆ")
            status_info.append("=" * 40)
            
            # æ„å»ºè¯¦ç»†çš„ä¿¡æ¯è¾“å‡º
            info_lines = [
                "ğŸ‰ GLM æç¤ºè¯ä¼˜åŒ–æˆåŠŸ",
                "",
                "ğŸ“‹ ä½¿ç”¨æ–¹æ¡ˆï¼š",
                f"   {used_method}",
                "",
                "ğŸ¤– API ä¿¡æ¯ï¼š",
                f"   æ¨¡å‹ï¼š{model_name}",
                f"   æ¸©åº¦ï¼š{temperature}",
                f"   Top-Pï¼š{top_p}",
                "",
                "ğŸ“Š é•¿åº¦ä¿¡æ¯ï¼š",
                f"   å®é™…ï¼š~{final_estimated_tokens} tokens ({final_word_count} è¯)",
                "",
                "ğŸ² ç§å­ï¼š",
                f"   {effective_seed}",
                "",
                "ğŸ’¡ æç¤ºï¼š",
                "   - ä¼˜åŒ–åçš„æç¤ºè¯å¯ä»¥ç›´æ¥ç”¨äºå›¾åƒç”Ÿæˆ",
                "   - å¯è¿æ¥åˆ°å…¶ä»–èŠ‚ç‚¹ç»§ç»­å¤„ç†",
            ]
            
            info = "\n".join(info_lines)
            
            return (optimized_prompt, original_prompt, info)
            
        except Exception as e:
            error_msg = f"âŒ é”™è¯¯ï¼šæç¤ºè¯ä¼˜åŒ–å¤±è´¥\n\né”™è¯¯è¯¦æƒ…ï¼š{str(e)}\n\nå¯èƒ½åŸå› ï¼š\n1. ç½‘ç»œè¿æ¥é—®é¢˜\n2. API è¯·æ±‚è¶…æ—¶\n3. ç³»ç»Ÿé”™è¯¯\n\nå»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¨åé‡è¯•\n3. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·æŸ¥çœ‹ç»ˆç«¯å®Œæ•´æ—¥å¿—"
            _log_error(error_msg)
            import traceback
            _log_error(traceback.format_exc())
            
            # æ·»åŠ çŠ¶æ€ä¿¡æ¯
            if status_info:
                error_msg = "\n".join(status_info) + "\n\n" + error_msg
            
            return ("", original_prompt, error_msg)


# ==================== èŠ‚ç‚¹æ³¨å†Œ ====================

NODE_CLASS_MAPPINGS = {
    "GLM_ImageToPrompt": GLM_ImageToPrompt,
    "GLM_PromptPolish": GLM_PromptPolish,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GLM_ImageToPrompt": "ğŸ” GLMå›¾åƒåæ¨ @ç‚®è€å¸ˆçš„å°è¯¾å ‚",
    "GLM_PromptPolish": "âœ¨ GLMæç¤ºè¯æ¶¦è‰² @ç‚®è€å¸ˆçš„å°è¯¾å ‚",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']

