"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’ Google Gemini 3 å¤šæ¨¡æ€å¯¹è¯èŠ‚ç‚¹ï¼ˆå®˜æ–¹+T8ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ åŠŸèƒ½è¯´æ˜ï¼š
   - æ”¯æŒ LLM å¯¹è¯ï¼ˆçº¯æ–‡æœ¬ï¼‰
   - æ”¯æŒå›¾åƒåæ¨ï¼ˆå¤šå›¾è¾“å…¥ï¼‰
   - æ”¯æŒè§†é¢‘åæ¨ï¼ˆVIDEO è¾“å…¥ï¼‰
   - æ”¯æŒéŸ³é¢‘åˆ†æï¼ˆAUDIO è¾“å…¥ï¼‰
   - æ•´åˆå¤šç§åŠŸèƒ½äºä¸€ä½“

ğŸ”§ æŠ€æœ¯ç‰¹æ€§ï¼š
   - æ”¯æŒ Google å®˜æ–¹ API å’Œ T8 ç¬¬ä¸‰æ–¹ API
   - åŒ API Key è¾“å…¥ï¼Œç¨³å®šå¯é 
   - å¼‚æ­¥æ¶æ„ï¼Œé«˜æ€§èƒ½
   - çµæ´»çš„é…ç½®ç³»ç»Ÿ

ğŸ‘¨â€ğŸ« ä½œè€…ï¼š@ç‚®è€å¸ˆçš„å°è¯¾å ‚
ğŸ“¦ ç‰ˆæœ¬ï¼šv1.3.3
ğŸ¨ ä¸»é¢˜ï¼šç´«è‰² (#8B4789)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import os
import json
import torch
import aiohttp
import asyncio
from typing import Tuple, Optional, List, Dict, Any

from .gemini3_client import encode_image_tensor, run_async
from .gemini3_file_client import GeminiFileClient, save_audio_to_file

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE_PATH = os.path.join(os.path.dirname(__file__), 'gemini3_config.json')

# åŠ è½½é…ç½®
API_PROVIDERS = ["Googleå®˜æ–¹", "T8"]
DEFAULT_PROVIDER = "Googleå®˜æ–¹"
ALL_MODELS = ["gemini-3-pro-preview", "gemini-3-flash", "gemini-2.5-flash", "gemini-2.5-pro"]
PROVIDER_MODELS = {}

if os.path.exists(CONFIG_FILE_PATH):
    try:
        with open(CONFIG_FILE_PATH, 'r', encoding='utf-8') as f:
            config = json.load(f)
            if "api_providers" in config and isinstance(config["api_providers"], dict):
                # è·å–æ‰€æœ‰æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
                all_models_set = set()
                for provider, details in config["api_providers"].items():
                    if "models" in details and isinstance(details["models"], list):
                        PROVIDER_MODELS[provider] = details["models"]
                        all_models_set.update(details["models"])
                if all_models_set:
                    ALL_MODELS = sorted(list(all_models_set))
            
            if "default_provider" in config:
                if config["default_provider"] == "google":
                    DEFAULT_PROVIDER = "Googleå®˜æ–¹"
                elif config["default_provider"] in ["comfly", "hk", "us", "T8"]:
                    DEFAULT_PROVIDER = "T8"
    except Exception as e:
        print(f"[Gemini3Chat] è­¦å‘Šï¼šæ— æ³•åŠ è½½é…ç½®: {e}")


class Gemini3MultimodalChatNode:
    """
    Google Gemini 3 å¤šæ¨¡æ€å¯¹è¯èŠ‚ç‚¹
    
    æ”¯æŒå¤šæ¨¡æ€è¾“å…¥å’Œå¯¹è¯
    æ”¯æŒ Google å®˜æ–¹ API å’Œ T8 ç¬¬ä¸‰æ–¹ API
    
    ä½œè€…ï¼š@ç‚®è€å¸ˆçš„å°è¯¾å ‚
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å–æ¨¡å‹åˆ—è¡¨
        t8_models = []
        google_models = []
        
        # T8 æ¨¡å‹
        for provider in ["comfly", "hk", "us", "T8"]:
            if provider in PROVIDER_MODELS:
                for model in PROVIDER_MODELS[provider]:
                    if model not in t8_models:
                        t8_models.append(model)
        
        # Google å®˜æ–¹æ¨¡å‹
        if "google" in PROVIDER_MODELS:
            google_models = PROVIDER_MODELS["google"]
        
        # åˆå¹¶æ‰€æœ‰æ¨¡å‹
        all_models = list(set(t8_models + google_models + ALL_MODELS))
        if not all_models:
            all_models = ["gemini-3-pro-preview", "gemini-3-flash"]
        
        # API æ¥æºæä¾›å•†ï¼ˆç”¨äºT8ï¼‰
        api_sources = ["comfly", "hk", "us"]
        
        return {
            "required": {
                "ğŸ¯ ç³»ç»Ÿè§’è‰²": ("STRING", {
                    "multiline": True,
                    "default": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘å†…å®¹ï¼Œå¹¶æä¾›è¯¦ç»†çš„æè¿°ã€‚",
                    "placeholder": "å®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸ºæ–¹å¼..."
                }),
                
                "ğŸ’¬ ç”¨æˆ·è¾“å…¥": ("STRING", {
                    "multiline": True,
                    "default": "è¯·è¯¦ç»†åˆ†æè¿™ä¸ªå†…å®¹ï¼ŒåŒ…æ‹¬æ‰€æœ‰ç»†èŠ‚",
                    "placeholder": "è¾“å…¥ä½ çš„é—®é¢˜æˆ–æŒ‡ä»¤..."
                }),
                
                "ğŸŒ APIæ¥æº": (API_PROVIDERS, {
                    "default": DEFAULT_PROVIDER
                }),
                
                "ğŸ¤– æ¨¡å‹é€‰æ‹©": (all_models, {
                    "default": all_models[0] if all_models else "gemini-3-pro-preview"
                }),
                
                "ğŸ”‘ Google API Key": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥ä½ çš„ Google API Key (é€‰æ‹©Googleå®˜æ–¹æ—¶ä½¿ç”¨)"
                }),
                
                "ğŸ”‘ T8Star API Key": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥ä½ çš„ T8Star API Key (é€‰æ‹©T8æ—¶ä½¿ç”¨)"
                }),
                
                "ğŸ“Š è¾“å‡ºè¯­è¨€": (["ä¸­æ–‡", "è‹±æ–‡"], {
                    "default": "ä¸­æ–‡"
                }),
            },
            "optional": {
                "ğŸ–¼ï¸ å›¾åƒ1": ("IMAGE",),
                "ğŸ–¼ï¸ å›¾åƒ2": ("IMAGE",),
                "ğŸ–¼ï¸ å›¾åƒ3": ("IMAGE",),
                "ğŸ–¼ï¸ å›¾åƒ4": ("IMAGE",),
                "ğŸ¬ è§†é¢‘": ("IMAGE",),
                "ğŸµ éŸ³é¢‘": ("AUDIO",),
                
                "ğŸŒ¡ï¸ æ¸©åº¦": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.01
                }),
                
                "ğŸ² top_p": ("FLOAT", {
                    "default": 0.90,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                
                "ğŸ“ æœ€å¤§ä»¤ç‰Œ": ("INT", {
                    "default": 2048,
                    "min": 1,
                    "max": 32768
                }),
                
                "ğŸŒ é•œåƒç«™": (api_sources, {
                    "default": "comfly",
                    "tooltip": "ä»…åœ¨é€‰æ‹©T8æ—¶æœ‰æ•ˆ"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("response",)
    FUNCTION = "process"
    CATEGORY = "ğŸ¤–dapaoAPI/Gemini"
    DESCRIPTION = "Gemini 3 å¤šæ¨¡æ€å¯¹è¯ | ä½œè€…: @ç‚®è€å¸ˆçš„å°è¯¾å ‚"
    OUTPUT_NODE = False
    
    def __init__(self):
        self.google_api_key = ''
        self.t8star_api_key = ''
    
    def save_api_key(self, google_key=None, t8star_key=None):
        """ä»…æ›´æ–°å†…å­˜ä¸­çš„APIå¯†é’¥ï¼Œä¸ä¿å­˜åˆ°æ–‡ä»¶"""
        if google_key and google_key.strip():
            self.google_api_key = google_key.strip()
        if t8star_key and t8star_key.strip():
            self.t8star_api_key = t8star_key.strip()
    
    def get_api_config(self, api_source: str, mirror_site: str = "comfly"):
        """è·å–APIé…ç½®"""
        if api_source == "Googleå®˜æ–¹":
            return {
                "base_url": "https://generativelanguage.googleapis.com",
                "provider": "google",
                "api_key": self.google_api_key
            }
        else:  # T8
            # ä»é…ç½®æ–‡ä»¶è·å–é•œåƒç«™URL
            config = {}
            if os.path.exists(CONFIG_FILE_PATH):
                try:
                    with open(CONFIG_FILE_PATH, 'r', encoding='utf-8') as f:
                        config = json.load(f)
                except:
                    pass
            
            base_url = "https://ai.comfly.chat/v1"
            if 'api_providers' in config and mirror_site in config['api_providers']:
                base_url = config['api_providers'][mirror_site].get('base_url', base_url)
            
            return {
                "base_url": base_url,
                "provider": mirror_site,
                "api_key": self.t8star_api_key
            }
    
    async def generate_async(
        self,
        api_config: dict,
        model: str,
        system_role: str,
        user_input: str,
        images: list,
        video,
        audio,
        temperature: float,
        top_p: float,
        max_tokens: int,
        language: str
    ) -> str:
        """å¼‚æ­¥ç”Ÿæˆå†…å®¹"""
        # æ·»åŠ è¯­è¨€æŒ‡ä»¤
        if language == "ä¸­æ–‡":
            language_instruction = "è¯·ç”¨ä¸­æ–‡è¯¦ç»†å›ç­”ï¼Œæä¾›å°½å¯èƒ½å®Œæ•´å’Œè¯¦ç»†çš„æè¿°ã€‚"
        else:
            language_instruction = "Please answer in English with detailed and comprehensive description."
        
        # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿè§’è‰²
        full_system_role = f"{system_role}\n\n{language_instruction}"
        
        print(f"[Gemini3Chat] APIæä¾›å•†: {api_config['provider']}")
        print(f"[Gemini3Chat] æ¨¡å‹: {model}")
        print(f"[Gemini3Chat] ç³»ç»Ÿè§’è‰²: {system_role[:50]}...")
        print(f"[Gemini3Chat] ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
        print(f"[Gemini3Chat] å›¾åƒæ•°é‡: {len(images)}")
        print(f"[Gemini3Chat] è§†é¢‘: {'æ˜¯' if video is not None else 'å¦'}")
        print(f"[Gemini3Chat] éŸ³é¢‘: {'æ˜¯' if audio is not None else 'å¦'}")
        
        # æ„å»ºå†…å®¹parts
        parts = []
        
        # æ·»åŠ å›¾åƒ
        if images:
            for img_tensor in images:
                if img_tensor is not None:
                    batch_size = img_tensor.shape[0]
                    for i in range(batch_size):
                        single_image = img_tensor[i]
                        image_base64 = encode_image_tensor(single_image)
                        parts.append({
                            "inline_data": {
                                "mime_type": "image/png",
                                "data": image_base64
                            }
                        })
        
        # æ·»åŠ è§†é¢‘å¸§ï¼ˆé‡‡æ ·æœ€å¤š10å¸§ï¼‰
        if video is not None:
            batch_size = video.shape[0]
            step = max(1, batch_size // 10)
            for i in range(0, batch_size, step):
                frame = video[i]
                image_base64 = encode_image_tensor(frame)
                parts.append({
                    "inline_data": {
                        "mime_type": "image/png",
                        "data": image_base64
                    }
                })
        
        # æ·»åŠ éŸ³é¢‘ï¼ˆä½¿ç”¨ File API ä¸Šä¼ ï¼‰
        if audio is not None:
            try:
                print(f"[Gemini3Chat] å¼€å§‹å¤„ç†éŸ³é¢‘...")
                temp_audio_path = save_audio_to_file(audio)
                print(f"[Gemini3Chat] éŸ³é¢‘ä¿å­˜åˆ°: {temp_audio_path}")
                
                file_client = GeminiFileClient(api_config['api_key'], api_config['provider'])
                file_uri = await file_client.upload_file(temp_audio_path)
                
                parts.append({
                    "file_data": {
                        "mime_type": "audio/wav",
                        "file_uri": file_uri
                    }
                })
                print(f"[Gemini3Chat] éŸ³é¢‘ä¸Šä¼ æˆåŠŸ: {file_uri}")
                
                try:
                    os.remove(temp_audio_path)
                except:
                    pass
            except Exception as e:
                print(f"[Gemini3Chat] éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
        
        # å°†ç³»ç»Ÿè§’è‰²å’Œç”¨æˆ·è¾“å…¥åˆå¹¶ï¼ˆGemini ä¸æ”¯æŒ system è§’è‰²ï¼‰
        combined_text = user_input
        if full_system_role.strip():
            combined_text = f"{full_system_role}\n\n{user_input}"
        
        # æ·»åŠ ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        parts.append({"text": combined_text})
        
        # æ„å»ºcontentsï¼ˆGemini API åªæ”¯æŒ user å’Œ model ä¸¤ç§è§’è‰²ï¼‰
        contents = [{
            "role": "user",
            "parts": parts
        }]
        
        # è°ƒç”¨API
        async with GeminiAPIClient(api_config) as client:
            result = await client.generate_content(
                model=model,
                contents=contents,
                temperature=temperature,
                top_p=top_p,
                max_tokens=max_tokens
            )
        
        # æå–å“åº”æ–‡æœ¬
        print(f"[Gemini3Chat] APIå“åº”: {str(result)[:200]}...")
        
        if 'candidates' in result and result['candidates']:
            candidate = result['candidates'][0]
            if 'content' in candidate and 'parts' in candidate['content']:
                response_parts = candidate['content']['parts']
                response_text = ""
                for part in response_parts:
                    if 'text' in part:
                        response_text += part['text']
                
                print(f"[Gemini3Chat] å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
                return response_text
        
        print(f"[Gemini3Chat] å®Œæ•´å“åº”: {result}")
        return "âŒ é”™è¯¯ï¼šAPIè¿”å›æ ¼å¼å¼‚å¸¸"
    
    def process(self, **kwargs):
        # æå–å‚æ•°
        system_role = kwargs.get("ğŸ¯ ç³»ç»Ÿè§’è‰²", "")
        user_input = kwargs.get("ğŸ’¬ ç”¨æˆ·è¾“å…¥", "")
        api_source = kwargs.get("ğŸŒ APIæ¥æº", "Googleå®˜æ–¹")
        model = kwargs.get("ğŸ¤– æ¨¡å‹é€‰æ‹©", "gemini-3-pro-preview")
        google_api_key = kwargs.get("ğŸ”‘ Google API Key", "")
        t8star_api_key = kwargs.get("ğŸ”‘ T8Star API Key", "")
        language = kwargs.get("ğŸ“Š è¾“å‡ºè¯­è¨€", "ä¸­æ–‡")
        mirror_site = kwargs.get("ğŸŒ é•œåƒç«™", "comfly")
        
        image1 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ1")
        image2 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ2")
        image3 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ3")
        image4 = kwargs.get("ğŸ–¼ï¸ å›¾åƒ4")
        video = kwargs.get("ğŸ¬ è§†é¢‘")
        audio = kwargs.get("ğŸµ éŸ³é¢‘")
        
        temperature = kwargs.get("ğŸŒ¡ï¸ æ¸©åº¦", 0.7)
        top_p = kwargs.get("ğŸ² top_p", 0.90)
        max_tokens = kwargs.get("ğŸ“ æœ€å¤§ä»¤ç‰Œ", 2048)
        
        # æ›´æ–°APIå¯†é’¥
        self.save_api_key(google_api_key, t8star_api_key)
        
        # è·å–APIé…ç½®
        api_config = self.get_api_config(api_source, mirror_site)
        
        # æ£€æŸ¥APIå¯†é’¥
        if not api_config['api_key']:
            return (f"âŒ é”™è¯¯ï¼šè¯·æä¾› {api_source} çš„APIå¯†é’¥",)
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒ
        images = [img for img in [image1, image2, image3, image4] if img is not None]
        
        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        try:
            response = run_async(
                self.generate_async(
                    api_config=api_config,
                    model=model,
                    system_role=system_role,
                    user_input=user_input,
                    images=images,
                    video=video,
                    audio=audio,
                    temperature=temperature,
                    top_p=top_p,
                    max_tokens=max_tokens,
                    language=language
                )
            )
            return (response,)
        except Exception as e:
            error_msg = f"âŒ APIé”™è¯¯: {str(e)}"
            print(f"[Gemini3Chat] {error_msg}")
            return (error_msg,)


class GeminiAPIClient:
    """Gemini API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_config: dict):
        self.api_key = api_config['api_key']
        self.base_url = api_config['base_url']
        self.provider = api_config['provider']
        self.session: Optional[aiohttp.ClientSession] = None
        self.timeout = 120
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def _get_endpoint(self, model: str) -> str:
        """è·å–APIç«¯ç‚¹URL"""
        if self.base_url.rstrip('/').endswith(('v1', 'v1beta', 'v1alpha')):
            return f"{self.base_url.rstrip('/')}/models/{model}:generateContent"
        else:
            return f"{self.base_url.rstrip('/')}/v1beta/models/{model}:generateContent"
    
    async def generate_content(
        self,
        model: str,
        contents: List[Dict[str, Any]],
        temperature: float = 0.7,
        top_p: float = 0.9,
        max_tokens: int = 2048
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå†…å®¹"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        url = self._get_endpoint(model)
        
        payload = {
            "contents": contents,
            "generationConfig": {
                "temperature": temperature,
                "topP": top_p,
                "maxOutputTokens": max_tokens
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": self.api_key
        }
        
        async with self.session.post(url, json=payload, headers=headers, timeout=self.timeout) as response:
            if response.status != 200:
                error_text = await response.text()
                raise Exception(f"Gemini APIé”™è¯¯ {response.status}: {error_text}")
            return await response.json()


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "Gemini3MultimodalChatNode": Gemini3MultimodalChatNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Gemini3MultimodalChatNode": "ğŸ’ Gemini 3 å¤šæ¨¡æ€å¯¹è¯ï¼ˆå®˜æ–¹+T8ï¼‰@ç‚®è€å¸ˆçš„å°è¯¾å ‚",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']
