"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¨ å›¾åƒç¼–è¾‘APIè°ƒç”¨èŠ‚ç‚¹
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ åŠŸèƒ½è¯´æ˜ï¼š
   - ä¸“é—¨ç”¨äºå›¾åƒç¼–è¾‘çš„APIè°ƒç”¨
   - æ”¯æŒå¤šä¸ªå›¾åƒè¾“å…¥(æœ€å¤š4ä¸ª)
   - çµæ´»çš„APIé…ç½®
   - æ”¯æŒ Nano Banana 2 / Gemini 3 é«˜çº§ç‰¹æ€§ (1K/2K/4K, é£æ ¼, è´¨é‡)
   - é›†æˆæ™ºèƒ½AIæ”¾å¤§ (Gigapixel/RealESRGAN)

ğŸ”§ æŠ€æœ¯ç‰¹æ€§ï¼š
   - åŸºäºé€šç”¨APIè°ƒç”¨é€»è¾‘
   - æ”¯æŒå›¾åƒbase64ç¼–ç 
   - æ”¯æŒå›¾åƒURLä¸‹è½½
   - å®Œæ•´çš„é”™è¯¯å¤„ç†
   - æ™ºèƒ½æç¤ºè¯å¤„ç†

ğŸ‘¨â€ğŸ« ä½œè€…ï¼š@ç‚®è€å¸ˆçš„å°è¯¾å ‚
ğŸ“¦ ç‰ˆæœ¬ï¼šv2.0.0 (Nano Banana Enhanced)
ğŸ¨ ä¸»é¢˜ï¼šç´«è‰² (#9B59B6)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import json
import requests
import base64
import io
import torch
import numpy as np
from PIL import Image
from typing import Tuple, Optional, Dict, Any, List
import re
import random
import time
import urllib3

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å°è¯•å¯¼å…¥ Google å®˜æ–¹ SDKï¼ˆå¯é€‰ï¼‰
try:
    from google import genai
    from google.genai import types as genai_types
    GOOGLE_SDK_AVAILABLE = True
    print("[dapaoAPI] âœ… Google Genai SDK å¯ç”¨")
except ImportError:
    GOOGLE_SDK_AVAILABLE = False
    print("[dapaoAPI] âš ï¸ Google Genai SDK æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ REST API")

# å°è¯•å¯¼å…¥æ™ºèƒ½æ”¾å¤§æ¨¡å—
try:
    from .ComfyUI_LLM_Banana.banana_upscale import smart_upscale
except ImportError:
    try:
        from ComfyUI_LLM_Banana.banana_upscale import smart_upscale
    except ImportError:
        smart_upscale = None
        print("âš ï¸ æœªæ‰¾åˆ° ComfyUI_LLM_Banana.banana_upscale æ¨¡å—ï¼Œæ™ºèƒ½æ”¾å¤§åŠŸèƒ½å°†ä¸å¯ç”¨")

# èŠ‚ç‚¹é¢œè‰² (ç´«è‰²)


class ImageEditAPINode:
    """
    å›¾åƒç¼–è¾‘APIè°ƒç”¨èŠ‚ç‚¹ (å¢å¼ºç‰ˆ)
    
    é›†æˆ Nano Banana 2 / Gemini 3 é«˜çº§ç‰¹æ€§
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        # å®šä¹‰é¢„è®¾é€‰é¡¹
        aspect_ratios = ["Auto", "1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]
        response_modalities = ["TEXT_AND_IMAGE", "IMAGE_ONLY"]
        output_resolutions = ["Auto (Model Default)", "1K", "2K", "4K"]
        quality_presets = ["standard", "hd", "ultra_hd", "ai_enhanced", "ai_ultra"]
        style_presets = ["vivid", "natural", "artistic", "cinematic", "photographic"]
        upscale_factors = ["1x (ä¸æ”¾å¤§)", "2x", "4x", "6x"]
        gigapixel_models = ["High Fidelity", "Standard", "Art & CG", "Lines", "Very Compressed", "Low Resolution", "Text & Shapes", "Redefine", "Recover"]
        
        return {
            "required": {
                "ğŸ’¬ æç¤ºè¯": ("STRING", {
                    "multiline": True,
                    "default": "è¯·æ ¹æ®è¿™äº›å›¾ç‰‡è¿›è¡Œä¸“ä¸šçš„å›¾åƒç¼–è¾‘",
                    "placeholder": "è¾“å…¥ä½ çš„ç¼–è¾‘æŒ‡ä»¤..."
                }),
                
                "ğŸŒ APIåœ°å€": ("STRING", {
                    "default": "https://api.tu-zi.com/v1/chat/completions",
                    "placeholder": "è¾“å…¥å®Œæ•´çš„API URL (Geminiæ¨¡å‹ç”¨/chat/completions, DALL-Eç”¨/images/edits)"
                }),
                
                "ğŸ”‘ APIå¯†é’¥": ("STRING", {
                    "default": "",
                    "placeholder": "è¾“å…¥ä½ çš„APIå¯†é’¥"
                }),
                
                "ğŸ¤– æ¨¡å‹åç§°": ("STRING", {
                    "default": "gemini-3-pro-image-preview",
                    "placeholder": "è¾“å…¥æ¨¡å‹åç§°ï¼Œå¦‚: gemini-3-pro-image-preview, dall-e-3"
                }),
                
                "ğŸ“¡ è¯·æ±‚æ–¹æ³•": (["POST", "GET", "PUT"], {
                    "default": "POST"
                }),
                
                "ğŸ” å¯†é’¥ä½ç½®": (["Header", "Query", "Body"], {
                    "default": "Header"
                }),
                
                "ğŸ“ å¯†é’¥å­—æ®µå": ("STRING", {
                    "default": "Authorization",
                    "placeholder": "å¦‚: Authorization, api_key, X-API-Key"
                }),
            },
            "optional": {
                "ğŸ–¼ï¸ å›¾åƒ1": ("IMAGE",),
                "ğŸ–¼ï¸ å›¾åƒ2": ("IMAGE",),
                "ğŸ–¼ï¸ å›¾åƒ3": ("IMAGE",),
                "ğŸ–¼ï¸ å›¾åƒ4": ("IMAGE",),
                
                # Gemini/Nano Banana é«˜çº§å‚æ•°
                "ğŸ“ å®½é«˜æ¯”": (aspect_ratios, {"default": "Auto"}),
                "ğŸ“Š å“åº”æ¨¡å¼": (response_modalities, {"default": "TEXT_AND_IMAGE"}),
                "ğŸ–¥ï¸ è¾“å‡ºåˆ†è¾¨ç‡": (output_resolutions, {"default": "Auto (Model Default)", "tooltip": "ä»…æ”¯æŒ Nano Banana 2 (Gemini 3) æ¨¡å‹"}),
                "ğŸ¨ ç”»è´¨é¢„è®¾": (quality_presets, {"default": "hd"}),
                "ğŸ­ é£æ ¼é¢„è®¾": (style_presets, {"default": "natural"}),
                
                # æ”¾å¤§è®¾ç½®
                "ğŸ” æ”¾å¤§å€æ•°": (upscale_factors, {"default": "1x (ä¸æ”¾å¤§)"}),
                "ğŸ§© æ”¾å¤§æ¨¡å‹": (gigapixel_models, {"default": "High Fidelity"}),

                "ğŸ¯ ç³»ç»Ÿè§’è‰²": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "å¯é€‰ï¼šå®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸ºæ–¹å¼..."
                }),
                
                "ğŸ¯ å“åº”æå–è·¯å¾„": ("STRING", {
                    "default": "",
                    "placeholder": "å¦‚: data.0.url (ç•™ç©ºè‡ªåŠ¨æ™ºèƒ½æå–)"
                }),
                
                "â±ï¸ è¶…æ—¶æ—¶é—´": ("INT", {
                    "default": 180,
                    "min": 1,
                    "max": 300,
                    "step": 1
                }),
                
                "ğŸ“‹ é¢å¤–Headers": ("STRING", {
                    "multiline": True,
                    "default": "{}",
                    "placeholder": "JSONæ ¼å¼çš„é¢å¤–Headers"
                }),
                
                "ğŸ“¦ é¢å¤–Bodyå‚æ•°": ("STRING", {
                    "multiline": True,
                    "default": "{}",
                    "placeholder": "JSONæ ¼å¼çš„é¢å¤–Bodyå‚æ•°"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("image", "response", "image_url", "raw_json")
    FUNCTION = "call_api"
    CATEGORY = "ğŸ¤–dapaoAPI"
    DESCRIPTION = "ğŸ¨é€šç”¨å›¾åƒç¼–è¾‘API (æµ‹è¯•ç‰ˆ) @ç‚®è€å¸ˆçš„å°è¯¾å ‚ | æ”¯æŒå¤šæ¨¡æ€å›¾åƒç¼–è¾‘ã€æ™ºèƒ½æç¤ºè¯å¤„ç†ã€AIæ”¾å¤§"
    OUTPUT_NODE = False
    
    def __init__(self):
        pass
    
    def call_api(
        self,
        **kwargs
    ) -> Tuple[torch.Tensor, str, str, str]:
        """è°ƒç”¨å›¾åƒç¼–è¾‘API"""
        # æå–åŸºç¡€å‚æ•°
        prompt = kwargs.get("ğŸ’¬ æç¤ºè¯", "")
        api_url = kwargs.get("ğŸŒ APIåœ°å€", "")
        api_key = kwargs.get("ğŸ”‘ APIå¯†é’¥", "")
        model_name = kwargs.get("ğŸ¤– æ¨¡å‹åç§°", "Auto (Latest Gemini 3 Pro) ğŸ¤–")
        method = kwargs.get("ğŸ“¡ è¯·æ±‚æ–¹æ³•", "POST")
        key_location = kwargs.get("ğŸ” å¯†é’¥ä½ç½®", "Header")
        key_field = kwargs.get("ğŸ“ å¯†é’¥å­—æ®µå", "Authorization")
        
        # æå–é«˜çº§å‚æ•°
        aspect_ratio = kwargs.get("ğŸ“ å®½é«˜æ¯”", "Auto")
        response_modality = kwargs.get("ğŸ“Š å“åº”æ¨¡å¼", "TEXT_AND_IMAGE")
        output_resolution = kwargs.get("ğŸ–¥ï¸ è¾“å‡ºåˆ†è¾¨ç‡", "Auto (Model Default)")
        quality = kwargs.get("ğŸ¨ ç”»è´¨é¢„è®¾", "hd")
        style = kwargs.get("ğŸ­ é£æ ¼é¢„è®¾", "natural")
        upscale_factor = kwargs.get("ğŸ” æ”¾å¤§å€æ•°", "1x (ä¸æ”¾å¤§)")
        gigapixel_model = kwargs.get("ğŸ§© æ”¾å¤§æ¨¡å‹", "High Fidelity")
        
        # å…¶ä»–å‚æ•°
        system_role = kwargs.get("ğŸ¯ ç³»ç»Ÿè§’è‰²", "")
        extract_path = kwargs.get("ğŸ¯ å“åº”æå–è·¯å¾„", "")
        timeout = kwargs.get("â±ï¸ è¶…æ—¶æ—¶é—´", 60)
        extra_headers_str = kwargs.get("ğŸ“‹ é¢å¤–Headers", "{}")
        extra_body_str = kwargs.get("ğŸ“¦ é¢å¤–Bodyå‚æ•°", "{}")
        
        # å›¾åƒè¾“å…¥
        images = [img for img in [kwargs.get(f"ğŸ–¼ï¸ å›¾åƒ{i}") for i in range(1, 5)] if img is not None]
        
        print(f"[dapaoAPI] APIåœ°å€: {api_url}")
        print(f"[dapaoAPI] æ¨¡å‹: {model_name}")
        print(f"[dapaoAPI] å›¾åƒæ•°é‡: {len(images)}")
        
        # 1. æ£€æµ‹æ¨¡å‹ç±»å‹
        is_nb2 = "gemini-3" in model_name.lower() or "pro-image" in model_name.lower()
        
        # 2. æ™ºèƒ½æç¤ºè¯å¤„ç† (å¤šå›¾å¼•ç”¨æ›¿æ¢)
        converted_prompt = prompt
        if len(images) >= 1: converted_prompt = converted_prompt.replace("å›¾1", "ç¬¬ä¸€å¼ å›¾ç‰‡")
        if len(images) >= 2: converted_prompt = converted_prompt.replace("å›¾2", "ç¬¬äºŒå¼ å›¾ç‰‡")
        if len(images) >= 3: converted_prompt = converted_prompt.replace("å›¾3", "ç¬¬ä¸‰å¼ å›¾ç‰‡")
        if len(images) >= 4: converted_prompt = converted_prompt.replace("å›¾4", "ç¬¬å››å¼ å›¾ç‰‡")
        
        # æ„å»ºå®Œæ•´æç¤ºè¯
        if len(images) > 1:
            # å¤šå›¾ç¼–è¾‘ï¼šå¼ºè°ƒæ‰€æœ‰å›¾ç‰‡çš„ä½¿ç”¨
            image_list = "ã€".join([f"ç¬¬{i+1}å¼ å›¾ç‰‡" for i in range(len(images))])
            full_prompt = f"""ã€å¤šå›¾ç¼–è¾‘ä»»åŠ¡ã€‘
æˆ‘ä¸Šä¼ äº† {len(images)} å¼ å›¾ç‰‡ï¼ˆ{image_list}ï¼‰ï¼Œè¯·åŠ¡å¿…ç»¼åˆå‚è€ƒæ‰€æœ‰å›¾ç‰‡è¿›è¡Œç¼–è¾‘ã€‚

ç”¨æˆ·æŒ‡ä»¤ï¼š
{converted_prompt}

é‡è¦è¦æ±‚ï¼š
1. å¿…é¡»åŒæ—¶å‚è€ƒæ‰€æœ‰ {len(images)} å¼ å›¾ç‰‡çš„å†…å®¹
2. é£æ ¼: {style}, ç”»è´¨: {quality}
3. ä»”ç»†åˆ†ææ¯å¼ å›¾ç‰‡çš„ç‰¹å¾ï¼Œå¹¶æŒ‰ç…§ç”¨æˆ·æŒ‡ä»¤è¿›è¡Œç²¾ç¡®ç»„åˆ
4. ç¡®ä¿ç”Ÿæˆçš„å›¾ç‰‡èåˆäº†æ‰€æœ‰è¾“å…¥å›¾ç‰‡çš„å…³é”®å…ƒç´ 
5. ä¿æŒè‡ªç„¶çœŸå®çš„è§†è§‰æ•ˆæœ
"""
        elif len(images) == 1:
            # å•å›¾ç¼–è¾‘
            full_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç¼–è¾‘å›¾ç‰‡ï¼š
{converted_prompt}

è¦æ±‚ï¼šé£æ ¼ {style}, ç”»è´¨ {quality}
"""
        else:
            full_prompt = prompt

        # 3. æ„å»ºAPIè¯·æ±‚
        # ğŸ” æ™ºèƒ½æ£€æµ‹ Gemini å®˜æ–¹ API å¹¶æ„å»ºå®Œæ•´ URL
        is_gemini_official = "generativelanguage.googleapis.com" in api_url
        
        if is_gemini_official:
            # Gemini å®˜æ–¹ APIï¼šè‡ªåŠ¨æ„å»ºå®Œæ•´ç«¯ç‚¹
            if ":generateContent" not in api_url:
                # ç§»é™¤æœ«å°¾çš„æ–œæ 
                base_url = api_url.rstrip('/')
                # æ„å»ºå®Œæ•´ç«¯ç‚¹
                api_url = f"{base_url}/v1beta/models/{model_name}:generateContent"
                print(f"[dapaoAPI] ğŸ”— Gemini å®˜æ–¹ API å®Œæ•´ç«¯ç‚¹: {api_url}")
        
        # ğŸ” ä¼˜å…ˆæ£€æµ‹æ˜¯å¦æ˜¯ /images/edits ç«¯ç‚¹ (éœ€è¦ä½¿ç”¨ multipart/form-data)
        is_images_edit_endpoint = "/images/edits" in api_url or "/images/edit" in api_url
        
        if is_images_edit_endpoint:
            # ä½¿ç”¨ multipart/form-data æ ¼å¼è°ƒç”¨ /images/edits ç«¯ç‚¹
            return self._handle_images_edit_endpoint(
                api_url, api_key, full_prompt, images, model_name,  # ä½¿ç”¨ full_prompt è€Œä¸æ˜¯ prompt
                key_location, key_field, timeout, extra_headers_str, extra_body_str,
                aspect_ratio, output_resolution, response_modality, quality, style,
                upscale_factor, gigapixel_model
            )
        
        # åˆ¤æ–­æ˜¯å¦ä¸º Gemini/Nano Banana ç³»åˆ—è°ƒç”¨ (é€šè¿‡æ¨¡å‹åæˆ–URLåˆ¤æ–­)
        is_gemini_api = "gemini" in model_name.lower() or "banana" in model_name.lower() or "google" in api_url.lower()
        
        if is_gemini_api:
            # ğŸ” åŒºåˆ† Gemini å®˜æ–¹ API å’Œä»£ç† API
            if is_gemini_official and GOOGLE_SDK_AVAILABLE:
                # ä¼˜å…ˆä½¿ç”¨å®˜æ–¹ SDK
                print(f"[dapaoAPI] ğŸš€ ä½¿ç”¨ Google å®˜æ–¹ SDK è°ƒç”¨")
                try:
                    return self._call_with_official_sdk(
                        api_key, model_name, full_prompt, images,
                        aspect_ratio, output_resolution, response_modality,
                        quality, style, system_role, upscale_factor, gigapixel_model, is_nb2
                    )
                except Exception as e:
                    print(f"[dapaoAPI] âŒ å®˜æ–¹ SDK è°ƒç”¨å¤±è´¥: {e}")
                    print(f"[dapaoAPI] ğŸ”„ å›é€€åˆ° REST API")
                    # ç»§ç»­ä½¿ç”¨ REST API
            
            if is_gemini_official:
                # Gemini å®˜æ–¹åŸç”Ÿæ ¼å¼ï¼šä½¿ç”¨ contents å’Œ parts
                print(f"[dapaoAPI] ä½¿ç”¨ Gemini å®˜æ–¹åŸç”Ÿæ ¼å¼")
                
                # æ„å»º parts æ•°ç»„ï¼šæ–‡æœ¬ + å›¾ç‰‡
                parts = [{"text": full_prompt}]
                
                for img_tensor in images:
                    # Tensor -> PIL -> Base64
                    single_image = img_tensor[0]
                    img_np = (single_image.cpu().numpy() * 255).astype(np.uint8)
                    pil_image = Image.fromarray(img_np)
                    pil_image = self._resize_image_if_needed(pil_image)
                    
                    buffered = io.BytesIO()
                    pil_image.save(buffered, format="JPEG", quality=85)
                    base64_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
                    
                    parts.append({
                        "inline_data": {
                            "mime_type": "image/jpeg",
                            "data": base64_str
                        }
                    })
                
                # Gemini åŸç”Ÿè¯·æ±‚æ ¼å¼
                body_data = {
                    "contents": [{
                        "parts": parts
                    }]
                }
                
                # æ·»åŠ  generationConfig
                generation_config = {}
                
                if response_modality == "IMAGE_ONLY":
                    generation_config["responseModalities"] = ["Image"]
                else:
                    generation_config["responseModalities"] = ["Text", "Image"]
                
                # å›¾åƒé…ç½®
                image_config = {}
                if aspect_ratio != "Auto":
                    image_config["aspectRatio"] = aspect_ratio
                if is_nb2 and output_resolution != "Auto (Model Default)":
                    image_config["imageSize"] = output_resolution
                if image_config:
                    generation_config["imageConfig"] = image_config
                
                if generation_config:
                    body_data["generationConfig"] = generation_config
                
                # ç³»ç»ŸæŒ‡ä»¤
                if system_role:
                    body_data["system_instruction"] = {
                        "parts": [{"text": system_role}]
                    }
                    
            else:
                # ä»£ç† APIï¼šä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
                print(f"[dapaoAPI] ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼ï¼ˆä»£ç†ï¼‰")
                
                messages = []
                if system_role:
                    messages.append({"role": "system", "content": system_role})
                
                # User Content (Text + Images)
                content_parts = [{"type": "text", "text": full_prompt}]
                
                for img_tensor in images:
                    single_image = img_tensor[0]
                    img_np = (single_image.cpu().numpy() * 255).astype(np.uint8)
                    pil_image = Image.fromarray(img_np)
                    pil_image = self._resize_image_if_needed(pil_image)
                    
                    buffered = io.BytesIO()
                    pil_image.save(buffered, format="PNG")
                    base64_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
                    
                    content_parts.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_str}"}
                    })
                
                messages.append({"role": "user", "content": content_parts})
                
                body_data = {
                    "model": model_name,
                    "messages": messages,
                    "stream": False
                }
                
                # Gemini ç‰¹æœ‰å‚æ•°
                generation_config = {}
                if response_modality == "IMAGE_ONLY":
                    generation_config["responseModalities"] = ["Image"]
                else:
                    generation_config["responseModalities"] = ["Text", "Image"]
                
                image_config = {}
                if aspect_ratio != "Auto":
                    image_config["aspectRatio"] = aspect_ratio
                if is_nb2 and output_resolution != "Auto (Model Default)":
                    image_config["imageSize"] = output_resolution
                if image_config:
                    generation_config["imageConfig"] = image_config
                    
                body_data["generationConfig"] = generation_config

        else:
            # æ™®é€š OpenAI Edit æ¥å£æˆ– DALL-E
            # ... (ä¿æŒåŸæœ‰é€»è¾‘æˆ–ç®€åŒ–)
            # ä¸ºç®€å•èµ·è§ï¼Œè¿™é‡Œç»Ÿä¸€ä½¿ç”¨ Chat æ¥å£æ ¼å¼ (GPT-4V é£æ ¼)ï¼Œå› ä¸ºç°ä»£å¤šæ¨¡æ€ç¼–è¾‘å¤§å¤šæ”¯æŒæ­¤æ ¼å¼
            # å¦‚æœæ˜¯æ—§ç‰ˆ DALL-E 2 Editï¼Œéœ€è¦ Multipartï¼Œè¿™é‡Œä¿ç•™æ—§é€»è¾‘çš„ç®€åŒ–ç‰ˆ
            
            is_dalle_edit = "dall-e-2" in model_name and ("edits" in api_url)
            
            if is_dalle_edit:
                # DALL-E Edit Logic (Multipart)
                return self._handle_dalle_edit(
                    api_url, api_key, prompt, images, model_name, 
                    key_location, key_field, timeout, extra_headers_str, extra_body_str
                )
            
            # é»˜è®¤å›é€€åˆ° Chat é€»è¾‘
            messages = [{"role": "user", "content": full_prompt}]
            # ... (åŒä¸Šï¼Œåªæ˜¯æ²¡æœ‰ Gemini ç‰¹æœ‰å‚æ•°)
            # é‡æ–°æ„å»ºç®€å•çš„ Chat Body
            body_data = {
                "model": model_name,
                "messages": [
                    {"role": "system", "content": system_role or "You are a helpful assistant."},
                    {"role": "user", "content": []}
                ]
            }
            
            content_list = [{"type": "text", "text": full_prompt}]
            for img_tensor in images:
                single_image = img_tensor[0]
                img_np = (single_image.cpu().numpy() * 255).astype(np.uint8)
                pil_image = Image.fromarray(img_np)
                buffered = io.BytesIO()
                pil_image.save(buffered, format="PNG")
                base64_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
                content_list.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_str}"}
                })
            body_data["messages"][1]["content"] = content_list

        # åˆå¹¶é¢å¤–å‚æ•°
        try:
            extra_body = json.loads(extra_body_str) if extra_body_str.strip() else {}
            body_data.update(extra_body)
        except:
            pass
            
        # Headers
        try:
            extra_headers = json.loads(extra_headers_str) if extra_headers_str.strip() else {}
        except:
            extra_headers = {}
            
        headers = {
            "Content-Type": "application/json",
            **extra_headers
        }
        
        # API Key
        if api_key:
            if key_location == "Header":
                if key_field.lower() == "authorization" and not api_key.startswith(("Bearer ", "Basic ")):
                    headers[key_field] = f"Bearer {api_key}"
                else:
                    headers[key_field] = api_key
            elif key_location == "Body":
                body_data[key_field] = api_key
        
        # å‘é€è¯·æ±‚
        try:
            print(f"[dapaoAPI] å‘é€è¯·æ±‚ä¸­...")
            response = requests.post(api_url, json=body_data, headers=headers, timeout=timeout)
            
            if response.status_code != 200:
                return (self._create_placeholder_image(), f"âŒ APIé”™è¯¯ ({response.status_code}): {response.text}", "", response.text)
                
            response_data = response.json()
            raw_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            # ğŸ” è°ƒè¯•ï¼šæ‰“å°å“åº”ç»“æ„
            print(f"[dapaoAPI] å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"[dapaoAPI] å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
            print(f"[dapaoAPI] å“åº”ç»“æ„é¢„è§ˆ: {list(response_data.keys())}")
            
            # å¦‚æœæœ‰ choicesï¼Œæ‰“å° content çš„å‰ 200 å­—ç¬¦
            if "choices" in response_data and len(response_data["choices"]) > 0:
                content = response_data["choices"][0].get("message", {}).get("content", "")
                print(f"[dapaoAPI] Content é¢„è§ˆ: {content[:200]}...")
            
            # æå–ç»“æœ
            print(f"[dapaoAPI] å¼€å§‹æå–å›¾åƒ...")
            image_tensor = self._extract_image_from_response(response_data)
            image_url = self._extract_image_url(response_data)
            
            # æå–æ–‡æœ¬å“åº” (ä½œä¸ºè¾…åŠ©ä¿¡æ¯)
            response_text = self._extract_text_from_response(response_data)
            if not response_text:
                response_text = raw_json
                
            if image_tensor is None:
                return (self._create_placeholder_image(), f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒ\n{response_text}", image_url, raw_json)
            
            # 4. æ™ºèƒ½æ”¾å¤§ (Post-Processing)
            if upscale_factor != "1x (ä¸æ”¾å¤§)" and smart_upscale:
                scale = int(upscale_factor.replace("x", "").split()[0])
                if scale > 1:
                    print(f"[dapaoAPI] å¼€å§‹ {scale}x æ™ºèƒ½æ”¾å¤§...")
                    # Tensor -> PIL
                    curr_img_np = (image_tensor[0].cpu().numpy() * 255).astype(np.uint8)
                    curr_pil = Image.fromarray(curr_img_np)
                    
                    target_w = curr_pil.width * scale
                    target_h = curr_pil.height * scale
                    
                    upscaled_pil = smart_upscale(curr_pil, target_w, target_h, gigapixel_model)
                    
                    if upscaled_pil:
                        # PIL -> Tensor
                        image_np = np.array(upscaled_pil).astype(np.float32) / 255.0
                        image_tensor = torch.from_numpy(image_np).unsqueeze(0)
                        print(f"[dapaoAPI] æ”¾å¤§å®Œæˆ: {image_tensor.shape}")
                        response_text += f"\n\nâœ… å·²å®Œæˆ {scale}x æ™ºèƒ½æ”¾å¤§ ({gigapixel_model})"
            
            return (image_tensor, response_text, image_url, raw_json)
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return (self._create_placeholder_image(), f"âŒ æ‰§è¡Œé”™è¯¯: {str(e)}", "", "{}")

    def _handle_dalle_edit(self, url, key, prompt, images, model, key_loc, key_field, timeout, ex_h, ex_b):
        # ç®€åŒ–çš„ DALL-E 2 Edit å®ç° (Multipart)
        # (ä»…ä½œä¸ºå…¼å®¹æ€§ä¿ç•™ï¼Œå®é™…é€»è¾‘å‚è€ƒåŸæ–‡ä»¶)
        # ç”±äºç”¨æˆ·ä¸»è¦å…³æ³¨ Gemini/Nano Bananaï¼Œè¿™é‡Œæš‚ä¸å±•å¼€ DALL-E å…·ä½“é€»è¾‘
        return (self._create_placeholder_image(), "DALL-E Edit Legacy Mode Not Fully Implemented in V2", "", "{}")

    def _resize_image_if_needed(self, pil_image, max_pixels=1048576):
        width, height = pil_image.size
        current_pixels = width * height
        if current_pixels > max_pixels:
            ratio = (max_pixels / current_pixels) ** 0.5
            new_width = int(width * ratio)
            new_height = int(height * ratio)
            return pil_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        return pil_image

    def _call_with_official_sdk(self, api_key, model_name, prompt, images,
                                 aspect_ratio, output_resolution, response_modality,
                                 quality, style, system_role, upscale_factor, gigapixel_model, is_nb2):
        """ä½¿ç”¨ Google å®˜æ–¹ SDK è°ƒç”¨ API"""
        # è§„èŒƒåŒ–æ¨¡å‹åç§°ï¼ˆGemini SDK éœ€è¦å®Œæ•´çš„æ¨¡å‹ IDï¼‰
        if not model_name.startswith("models/"):
            # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼Œè½¬æ¢ä¸ºå°å†™
            normalized_name = model_name.lower().replace(" ", "-").replace("_", "-")
            # å¦‚æœæ˜¯ç®€çŸ­åç§°ï¼Œæ·»åŠ  models/ å‰ç¼€
            model_name = f"models/{normalized_name}"
        
        print(f"[dapaoAPI] ä½¿ç”¨æ¨¡å‹: {model_name}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = genai.Client(api_key=api_key)
        
        # æ„å»º parts æ•°ç»„
        parts = [{"text": prompt}]
        
        for img_tensor in images:
            single_image = img_tensor[0]
            img_np = (single_image.cpu().numpy() * 255).astype(np.uint8)
            pil_image = Image.fromarray(img_np)
            pil_image = self._resize_image_if_needed(pil_image)
            
            buffered = io.BytesIO()
            pil_image.save(buffered, format="JPEG", quality=85)
            base64_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
            
            parts.append({
                "inline_data": {
                    "mime_type": "image/jpeg",
                    "data": base64_str
                }
            })
        
        # æ„å»ºé…ç½®
        config_params = {
            'temperature': 0.7,
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 8192,
        }
        
        # å“åº”æ¨¡å¼
        if response_modality == "IMAGE_ONLY":
            config_params['response_modalities'] = ['Image']
        else:
            config_params['response_modalities'] = ['Text', 'Image']
        
        # å›¾åƒé…ç½®
        image_config_params = {}
        if aspect_ratio != "Auto":
            image_config_params['aspect_ratio'] = aspect_ratio
        if is_nb2 and output_resolution != "Auto (Model Default)":
            image_config_params['image_size'] = output_resolution
        if image_config_params:
            config_params['image_config'] = genai_types.ImageConfig(**image_config_params)
        
        # ç³»ç»ŸæŒ‡ä»¤
        if system_role:
            config_params['system_instruction'] = system_role
        
        official_config = genai_types.GenerateContentConfig(**config_params)
        
        # è°ƒç”¨ API
        print(f"[dapaoAPI] ğŸ“¡ è°ƒç”¨å®˜æ–¹ SDK...")
        response = client.models.generate_content(
            model=model_name,
            contents=[{"parts": parts}],
            config=official_config
        )
        
        # æå–å›¾åƒ
        image_tensor = None
        response_text = ""
        
        if hasattr(response, 'candidates') and response.candidates:
            for candidate in response.candidates:
                if hasattr(candidate, 'content') and candidate.content and hasattr(candidate.content, 'parts'):
                    for part in candidate.content.parts:
                        # æå–æ–‡æœ¬
                        if hasattr(part, 'text') and part.text:
                            response_text += part.text
                        # æå–å›¾åƒ
                        elif hasattr(part, 'inline_data') and part.inline_data:
                            if hasattr(part.inline_data, 'data'):
                                data = part.inline_data.data
                                if hasattr(data, 'decode'):
                                    data = base64.b64encode(data).decode('utf-8')
                                image_tensor = self._decode_base64_to_tensor(data)
                                print(f"[dapaoAPI] âœ… æˆåŠŸæå–å›¾åƒ")
        
        # æ™ºèƒ½æ”¾å¤§
        if image_tensor is not None and upscale_factor and upscale_factor != "1x (ä¸æ”¾å¤§)" and smart_upscale:
            try:
                scale = int(upscale_factor.replace("x", "").strip().split()[0])
                if scale > 1:
                    print(f"[dapaoAPI] ğŸ” å¼€å§‹ {scale}x æ™ºèƒ½æ”¾å¤§")
                    img_np = (image_tensor[0].cpu().numpy() * 255).astype(np.uint8)
                    pil_img = Image.fromarray(img_np)
                    target_w = pil_img.width * scale
                    target_h = pil_img.height * scale
                    upscaled = smart_upscale(pil_img, target_w, target_h, gigapixel_model)
                    if upscaled:
                        image_tensor = torch.from_numpy(np.array(upscaled).astype(np.float32) / 255.0).unsqueeze(0)
                        print(f"[dapaoAPI] âœ… æ™ºèƒ½æ”¾å¤§å®Œæˆ")
            except Exception as e:
                print(f"[dapaoAPI] âš ï¸ æ™ºèƒ½æ”¾å¤§å¤±è´¥: {e}")
        
        if image_tensor is None:
            image_tensor = self._create_placeholder_image()
            response_text = "âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ•°æ®"
        
        return (image_tensor, response_text, "", "")
    
    def _create_placeholder_image(self) -> torch.Tensor:
        return torch.from_numpy(np.ones((64, 64, 3), dtype=np.float32) * 0.5).unsqueeze(0)
    
    def _handle_images_edit_endpoint(self, api_url, api_key, prompt, images, model_name,
                                     key_location, key_field, timeout, extra_headers_str, extra_body_str,
                                     aspect_ratio, output_resolution, response_modality, quality, style,
                                     upscale_factor, gigapixel_model):
        """
        å¤„ç† /images/edits ç«¯ç‚¹ (ä½¿ç”¨ multipart/form-data æ ¼å¼)
        å‚è€ƒï¼šhttps://wiki.tu-zi.com/s/8c61a536-7a59-4410-a5e2-8dab3d041958/doc/2gemini-3-pro-image-preview-wCmFtI3Tm5
        """
        print(f"[dapaoAPI] æ£€æµ‹åˆ° /images/edits ç«¯ç‚¹ï¼Œä½¿ç”¨ multipart/form-data æ ¼å¼")
        
        # å‡†å¤‡ Headers
        try:
            extra_headers = json.loads(extra_headers_str) if extra_headers_str.strip() else {}
        except:
            extra_headers = {}
        
        headers = {**extra_headers}
        
        # API Key
        if api_key:
            if key_location == "Header":
                if key_field.lower() == "authorization" and not api_key.startswith(("Bearer ", "Basic ")):
                    headers[key_field] = f"Bearer {api_key}"
                else:
                    headers[key_field] = api_key
        
        # å‡†å¤‡ form data
        data = {
            "model": model_name,
            "prompt": prompt,
        }
        
        # æ·»åŠ é¢å¤–å‚æ•°
        try:
            extra_body = json.loads(extra_body_str) if extra_body_str.strip() else {}
            data.update(extra_body)
        except:
            pass
        
        # å‡†å¤‡å›¾ç‰‡æ–‡ä»¶ (multipart/form-data)
        files = []
        for idx, img_tensor in enumerate(images):
            single_image = img_tensor[0]
            img_np = (single_image.cpu().numpy() * 255).astype(np.uint8)
            pil_image = Image.fromarray(img_np)
            
            # å°†å›¾ç‰‡ä¿å­˜åˆ° BytesIO
            buffered = io.BytesIO()
            pil_image.save(buffered, format="PNG")
            buffered.seek(0)
            
            # æ·»åŠ åˆ° files (ç¬¬ä¸€å¼ å›¾ç‰‡ç”¨ 'image'ï¼Œåç»­ç”¨ 'image2', 'image3' ç­‰)
            field_name = "image" if idx == 0 else f"image{idx + 1}"
            files.append((field_name, (f"image{idx + 1}.png", buffered, "image/png")))
            print(f"[dapaoAPI] æ·»åŠ å›¾ç‰‡ {idx + 1}: {pil_image.size}")
        
        # å‘é€è¯·æ±‚
        try:
            print(f"[dapaoAPI] å‘é€ multipart/form-data è¯·æ±‚åˆ°: {api_url}")
            print(f"[dapaoAPI] æ¨¡å‹: {model_name}")
            print(f"[dapaoAPI] å›¾ç‰‡æ•°é‡: {len(images)}")
            print(f"[dapaoAPI] å®Œæ•´æç¤ºè¯:\n{prompt}")
            
            response = requests.post(
                api_url,
                headers=headers,
                data=data,
                files=files,
                timeout=timeout,
                verify=False
            )
            
            print(f"[dapaoAPI] å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"[dapaoAPI] å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
            
            if response.status_code != 200:
                return (self._create_placeholder_image(), f"âŒ APIé”™è¯¯ ({response.status_code}): {response.text}", "", response.text)
            
            response_data = response.json()
            raw_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            print(f"[dapaoAPI] å“åº”ç»“æ„: {list(response_data.keys())}")
            
            # å¦‚æœæœ‰ choicesï¼Œæ‰“å° content
            if "choices" in response_data and len(response_data["choices"]) > 0:
                content = response_data["choices"][0].get("message", {}).get("content", "")
                print(f"[dapaoAPI] Content é¢„è§ˆ: {content[:200]}...")
            
            # æå–ç»“æœ
            print(f"[dapaoAPI] å¼€å§‹æå–å›¾åƒ...")
            image_tensor = self._extract_image_from_response(response_data)
            image_url = self._extract_image_url(response_data)
            response_text = self._extract_text_from_response(response_data)
            
            if not response_text:
                response_text = raw_json
            
            if image_tensor is None:
                return (self._create_placeholder_image(), f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ•°æ®\n{response_text}", image_url, raw_json)
            
            # æ™ºèƒ½æ”¾å¤§ (å¦‚æœéœ€è¦)
            if upscale_factor and upscale_factor != "1x (ä¸æ”¾å¤§)" and smart_upscale:
                try:
                    scale = int(upscale_factor.replace("x", "").strip().split()[0])
                    if scale > 1:
                        print(f"[dapaoAPI] å¼€å§‹ {scale}x æ™ºèƒ½æ”¾å¤§ï¼Œæ¨¡å‹: {gigapixel_model}")
                        # è½¬æ¢ä¸º PIL
                        img_np = (image_tensor[0].cpu().numpy() * 255).astype(np.uint8)
                        pil_img = Image.fromarray(img_np)
                        target_w = pil_img.width * scale
                        target_h = pil_img.height * scale
                        upscaled = smart_upscale(pil_img, target_w, target_h, gigapixel_model)
                        if upscaled:
                            image_tensor = torch.from_numpy(np.array(upscaled).astype(np.float32) / 255.0).unsqueeze(0)
                            print(f"[dapaoAPI] âœ… æ™ºèƒ½æ”¾å¤§å®Œæˆ: {upscaled.size}")
                except Exception as e:
                    print(f"[dapaoAPI] âš ï¸ æ™ºèƒ½æ”¾å¤§å¤±è´¥: {e}")
            
            return (image_tensor, response_text, image_url, raw_json)
            
        except requests.exceptions.Timeout:
            return (self._create_placeholder_image(), f"â±ï¸ è¯·æ±‚è¶…æ—¶ ({timeout}ç§’)", "", "")
        except Exception as e:
            import traceback
            error_msg = f"âŒ è¯·æ±‚å¤±è´¥: {e}\n{traceback.format_exc()}"
            print(f"[dapaoAPI] {error_msg}")
            return (self._create_placeholder_image(), error_msg, "", "")

    def _extract_image_from_response(self, data) -> Optional[torch.Tensor]:
        # å¢å¼ºçš„å›¾åƒæå–é€»è¾‘
        try:
            print(f"[dapaoAPI] ğŸ” å¼€å§‹å›¾åƒæå–ï¼Œå“åº”é”®: {list(data.keys())}")
            
            # 1. Google Gemini æ ¼å¼ (candidates.content.parts)
            if "candidates" in data:
                print(f"[dapaoAPI] âœ“ æ£€æµ‹åˆ° candidates å­—æ®µ")
                for candidate in data["candidates"]:
                    if "content" in candidate and "parts" in candidate["content"]:
                        for part in candidate["content"]["parts"]:
                            # Inline Data
                            if "inline_data" in part:
                                b64_data = part["inline_data"].get("data", "")
                                if b64_data:
                                    print(f"[dapaoAPI] âœ“ æ‰¾åˆ° inline_dataï¼Œé•¿åº¦: {len(b64_data)}")
                                    return self._decode_base64_to_tensor(b64_data)
                            # Image URL (rare but possible in some proxies)
                            if "image_url" in part:
                                print(f"[dapaoAPI] âœ“ æ‰¾åˆ° image_url")
                                return self._download_image_from_url(part["image_url"]["url"])
            
            # 2. OpenAI / Generic æ ¼å¼
            if "data" in data and isinstance(data["data"], list):
                print(f"[dapaoAPI] âœ“ æ£€æµ‹åˆ° data æ•°ç»„")
                item = data["data"][0]
                if "b64_json" in item:
                    print(f"[dapaoAPI] âœ“ æ‰¾åˆ° b64_json")
                    return self._decode_base64_to_tensor(item["b64_json"])
                if "url" in item:
                    print(f"[dapaoAPI] âœ“ æ‰¾åˆ° url")
                    return self._download_image_from_url(item["url"])
            
            # 3. ç›´æ¥ URL æˆ– Base64
            if "image" in data:
                print(f"[dapaoAPI] âœ“ æ‰¾åˆ° image å­—æ®µ")
                return self._decode_or_download(data["image"])
            if "images" in data and len(data["images"]) > 0:
                print(f"[dapaoAPI] âœ“ æ‰¾åˆ° images æ•°ç»„")
                return self._decode_or_download(data["images"][0])
            if "url" in data:
                print(f"[dapaoAPI] âœ“ æ‰¾åˆ° url å­—æ®µ")
                return self._download_image_from_url(data["url"])
            
            # 4. OpenAI Chat Completion æ ¼å¼ (ä» content ä¸­æå– Markdown å›¾ç‰‡é“¾æ¥)
            # å¾ˆå¤šä»£ç†å•†ä¼šå°† Gemini ç”Ÿæˆçš„å›¾ç‰‡ä»¥ Markdown é“¾æ¥å½¢å¼æ”¾åœ¨ content ä¸­
            if "choices" in data and len(data["choices"]) > 0:
                print(f"[dapaoAPI] âœ“ æ£€æµ‹åˆ° choices å­—æ®µ")
                content = data["choices"][0].get("message", {}).get("content", "")
                print(f"[dapaoAPI] Content é•¿åº¦: {len(content)}")
                if content:
                    # åŒ¹é… Markdown å›¾ç‰‡è¯­æ³• ![alt](url)
                    import re
                    print(f"[dapaoAPI] å°è¯•åŒ¹é… Markdown å›¾ç‰‡...")
                    # ä¼˜å…ˆåŒ¹é… markdown å›¾ç‰‡é“¾æ¥
                    match = re.search(r'!\[.*?\]\((.*?)\)', content)
                    if match:
                        image_url = match.group(1)
                        print(f"[dapaoAPI] âœ“ ä»Markdownä¸­æå–åˆ°å›¾ç‰‡URL: {image_url[:80]}...")
                        result = self._download_image_from_url(image_url)
                        if result is not None:
                            print(f"[dapaoAPI] âœ“ å›¾ç‰‡ä¸‹è½½æˆåŠŸ")
                            return result
                        else:
                            print(f"[dapaoAPI] âœ— å›¾ç‰‡ä¸‹è½½å¤±è´¥")
                    else:
                        print(f"[dapaoAPI] âœ— æœªåŒ¹é…åˆ° Markdown æ ¼å¼")
                    
                    # å…¶æ¬¡åŒ¹é…ä»»æ„ https:// URL (æ”¯æŒå„ç§å›¾åºŠåŸŸå)
                    print(f"[dapaoAPI] å°è¯•åŒ¹é…é€šç”¨ URL...")
                    if "https://" in content or "http://" in content:
                        # æ›´å®½æ¾çš„åŒ¹é…ï¼Œæ”¯æŒå„ç§å›¾åºŠåŸŸå
                        # åŒ¹é… http(s)://... ç›´åˆ°é‡åˆ°ç©ºæ ¼ã€å³æ‹¬å·ã€å¼•å·ç­‰
                        url_match = re.search(r'(https?://[^\s\)\]\"\'\<\>]+)', content)
                        if url_match:
                            image_url = url_match.group(1)
                            # æ¸…ç†å¯èƒ½è·Ÿéšçš„æ ‡ç‚¹ç¬¦å·
                            image_url = image_url.rstrip(').,;:!?\"\']')
                            print(f"[dapaoAPI] âœ“ æå–åˆ°å›¾ç‰‡URL: {image_url}")
                            result = self._download_image_from_url(image_url)
                            if result is not None:
                                print(f"[dapaoAPI] âœ“ å›¾ç‰‡ä¸‹è½½æˆåŠŸ")
                                return result
                            else:
                                print(f"[dapaoAPI] âœ— å›¾ç‰‡ä¸‹è½½å¤±è´¥")
                        else:
                            print(f"[dapaoAPI] âœ— æœªåŒ¹é…åˆ° URL")
                    else:
                        print(f"[dapaoAPI] âœ— Content ä¸­ä¸åŒ…å« http(s) é“¾æ¥")

            print(f"[dapaoAPI] âœ— æ‰€æœ‰æå–æ–¹æ³•å‡å¤±è´¥")
            return None
        except Exception as e:
            print(f"[dapaoAPI] âŒ å›¾åƒæå–å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _extract_text_from_response(self, data) -> str:
        try:
            if "choices" in data and len(data["choices"]) > 0:
                return data["choices"][0].get("message", {}).get("content", "")
            if "candidates" in data and len(data["candidates"]) > 0:
                parts = data["candidates"][0].get("content", {}).get("parts", [])
                text_parts = [p.get("text", "") for p in parts if "text" in p]
                return "\n".join(text_parts)
            return ""
        except:
            return ""

    def _extract_image_url(self, data) -> str:
        # ç®€åŒ–ç‰ˆURLæå–
        try:
            if "data" in data and isinstance(data["data"], list):
                return data["data"][0].get("url", "")
            
            # å°è¯•ä» Markdown å†…å®¹ä¸­æå–
            if "choices" in data and len(data["choices"]) > 0:
                content = data["choices"][0].get("message", {}).get("content", "")
                if content:
                    import re
                    match = re.search(r'!\[.*?\]\((.*?)\)', content)
                    if match:
                        return match.group(1)
            
            return data.get("url", "") or data.get("image_url", "")
        except:
            return ""

    def _decode_base64_to_tensor(self, b64_str) -> torch.Tensor:
        if "," in b64_str: b64_str = b64_str.split(",")[1]
        img_bytes = base64.b64decode(b64_str)
        img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
        return torch.from_numpy(np.array(img).astype(np.float32) / 255.0).unsqueeze(0)

    def _download_image_from_url(self, url) -> torch.Tensor:
        try:
            print(f"[dapaoAPI] ğŸŒ å¼€å§‹ä¸‹è½½å›¾ç‰‡: {url}")
            resp = requests.get(url, timeout=60, verify=False)  # æœ‰äº›ä»£ç†å¯èƒ½æœ‰SSLé—®é¢˜
            print(f"[dapaoAPI] ğŸ“¥ ä¸‹è½½çŠ¶æ€ç : {resp.status_code}, å¤§å°: {len(resp.content)} bytes")
            
            if resp.status_code != 200:
                print(f"[dapaoAPI] âŒ ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
                return None
                
            img = Image.open(io.BytesIO(resp.content)).convert("RGB")
            print(f"[dapaoAPI] âœ… å›¾ç‰‡è§£ææˆåŠŸ: {img.size}")
            tensor = torch.from_numpy(np.array(img).astype(np.float32) / 255.0).unsqueeze(0)
            print(f"[dapaoAPI] âœ… è½¬æ¢ä¸ºTensoræˆåŠŸ: {tensor.shape}")
            return tensor
        except Exception as e:
            print(f"[dapaoAPI] âŒ å›¾ç‰‡ä¸‹è½½/è§£æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
            
    def _decode_or_download(self, data) -> torch.Tensor:
        if data.startswith("http"): return self._download_image_from_url(data)
        return self._decode_base64_to_tensor(data)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ImageEditAPINode": ImageEditAPINode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageEditAPINode": "ğŸ¨é€šç”¨å›¾åƒç¼–è¾‘API (æµ‹è¯•ç‰ˆ) @ç‚®è€å¸ˆçš„å°è¯¾å ‚",
}
