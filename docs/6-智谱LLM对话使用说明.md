# 智谱 LLM 对话节点使用说明

## 📖 节点简介

智谱 LLM 对话节点基于智谱 AI 的 GLM 系列大语言模型，提供强大的中文理解和生成能力，在多项中文NLP任务中表现优异。

## 🎯 主要功能

- ✅ 深度中文理解与对话
- ✅ 专业内容创作
- ✅ 代码生成与调试
- ✅ 逻辑推理与分析
- ✅ 系统提示词自定义
- ✅ 种子控制（固定/随机/递增）

## 📝 参数说明

### 必填参数

| 参数名 | 类型 | 说明 |
|--------|------|------|
| **用户消息 (user_message)** | STRING | 您的问题或指令 |
| **API Key** | STRING | 智谱 AI API 密钥 |

### 可选参数

| 参数名 | 类型 | 默认值 | 说明 |
|--------|------|--------|------|
| **系统提示词 (system_prompt)** | STRING | 空 | 设定AI的角色和行为 |
| **模型 (model)** | DROPDOWN | GLM-4.5-Flash | 使用的 GLM 模型 |
| **种子控制 (seed_control)** | DROPDOWN | 随机 | 种子生成方式 |
| **种子值 (seed)** | INT | 0 | 固定种子值（1-2147483647） |
| **温度 (temperature)** | FLOAT | 0.7 | 输出随机性（0.0-1.0） |
| **top_p** | FLOAT | 0.9 | 核采样参数（0.0-1.0） |
| **最大令牌数 (max_tokens)** | INT | 2000 | 输出最大长度 |

## 🤖 模型选择

| 模型名称 | 特点 | 适用场景 |
|----------|------|----------|
| **GLM-4.5-Flash** ⭐ | 速度最快，性能优异 | 日常对话、快速响应场景 |
| **GLM-4-Plus** | 能力最强，深度理解 | 复杂推理、专业内容 |
| **GLM-4-Air** | 平衡版本 | 通用场景、成本敏感 |
| **GLM-4-Flash** | 快速响应 | 实时对话、批量处理 |
| **GLM-4** | 标准版本 | 标准需求 |

### 模型对比

| 维度 | GLM-4.5-Flash | GLM-4-Plus | GLM-4-Air | GLM-4-Flash |
|------|---------------|------------|-----------|-------------|
| **速度** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **能力** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |
| **成本** | 💰💰 | 💰💰💰💰 | 💰 | 💰💰 |
| **推荐度** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |

## 💬 系统提示词 (System Prompt)

系统提示词用于设定AI的角色、专业领域和输出风格。

### 精选示例

#### 1. 编程专家
```
你是一位资深的全栈工程师，精通Python、JavaScript、数据库等技术。请提供高质量的代码示例，包含详细注释和最佳实践说明。代码要求：简洁、高效、可维护。
```

#### 2. 学术写作助手
```
你是一位学术写作专家，擅长撰写论文、研究报告。请使用严谨的学术语言，引用时注明来源，逻辑清晰，论证充分。格式要求：标题、摘要、正文、参考文献。
```

#### 3. 创意文案策划
```
你是一位富有创意的广告文案策划，擅长品牌故事、营销文案。请使用生动有感染力的语言，把握用户痛点，突出产品价值。风格：年轻、活力、接地气。
```

#### 4. 数据分析师
```
你是一位专业的数据分析师，擅长从数据中发现洞察，提供决策建议。请使用图表、数据支撑观点，分析全面客观。输出格式：现状分析、趋势预测、行动建议。
```

#### 5. 教育导师
```
你是一位耐心的教育专家，擅长用浅显易懂的语言解释复杂概念。请采用苏格拉底式提问法，引导学生思考。风格：循循善诱、由浅入深、举例丰富。
```

#### 6. 产品经理
```
你是一位经验丰富的产品经理，擅长需求分析、功能设计。请从用户视角思考，平衡商业价值与用户体验。输出包含：需求背景、解决方案、预期效果。
```

## 🎲 种子控制

| 控制方式 | 说明 | 适用场景 |
|----------|------|----------|
| **随机** | 每次回复略有不同 | 创意探索、多角度思考 |
| **固定** | 使用固定种子，结果一致 | A/B测试、效果对比 |
| **递增** | 种子值递增，渐进变化 | 生成系列内容 |

⚠️ **重要提示**：智谱AI种子值范围为 1 - 2,147,483,647，超出范围会自动映射。

## 💡 使用场景

### 1. 深度问答
```
用户消息："请详细解释量子纠缠现象，包括原理、应用和实验证据"
系统提示词："你是物理学教授，擅长用通俗语言解释复杂物理现象"
模型：GLM-4-Plus

输出：深入浅出的量子纠缠解释
```

### 2. 代码生成与优化
```
用户消息："
请用Python实现一个LRU缓存：
- 支持get和put操作
- 时间复杂度O(1)
- 包含完整测试用例
"
系统提示词："你是Python专家，代码简洁高效，包含类型注解和文档字符串"
模型：GLM-4.5-Flash

输出：完整的LRU缓存实现
```

### 3. 学术论文写作
```
用户消息："请撰写一篇关于'AI在医疗诊断中的应用'的文献综述，2000字"
系统提示词："你是医学AI研究者，擅长撰写学术综述，引用权威文献"
模型：GLM-4-Plus
max_tokens：3000

输出：规范的文献综述
```

### 4. 商业文案创作
```
用户消息："为一款面向年轻人的智能手表撰写产品文案，突出健康监测功能"
系统提示词："你是资深文案策划，擅长抓住年轻人的兴趣点"
模型：GLM-4.5-Flash
temperature：0.9

输出：吸引人的产品文案
```

### 5. 数据分析报告
```
用户消息："分析这份销售数据，提供增长策略建议：[数据]"
系统提示词："你是数据分析专家，善于发现趋势和问题，提供可执行的建议"
模型：GLM-4-Plus
temperature：0.5

输出：详细的分析报告
```

### 6. 教学辅导
```
用户消息："我不理解递归算法，请用简单的例子帮我理解"
系统提示词："你是编程导师，善于用生活中的例子解释算法"
模型：GLM-4.5-Flash
temperature：0.7

输出：易懂的递归讲解
```

### 7. 内容翻译
```
用户消息："请将以下技术文档翻译成中文，保持专业术语准确：[英文文档]"
系统提示词："你是技术翻译专家，译文准确流畅，符合中文表达习惯"
模型：GLM-4-Plus
temperature：0.3

输出：高质量中文翻译
```

### 8. 创意头脑风暴
```
用户消息："为一家环保科技公司设计10个创新的宣传活动方案"
系统提示词："你是创意总监，思维发散，善于策划有影响力的活动"
模型：GLM-4.5-Flash
temperature：0.95

输出：多样化的创意方案
```

## ⚙️ 参数调优指南

### 标准对话模式
```
模型：GLM-4.5-Flash
temperature：0.7
top_p：0.9
max_tokens：2000
seed_control：随机

✅ 适用：日常对话、通用问答、内容生成
```

### 创意写作模式
```
模型：GLM-4-Plus
temperature：0.9
top_p：0.95
max_tokens：3000
seed_control：随机

✅ 适用：文学创作、广告文案、创意策划
```

### 精确输出模式
```
模型：GLM-4-Plus
temperature：0.3
top_p：0.8
max_tokens：2000
seed_control：固定

✅ 适用：代码生成、数据分析、技术文档
```

### 快速响应模式
```
模型：GLM-4-Flash
temperature：0.5
top_p：0.85
max_tokens：1000
seed_control：随机

✅ 适用：实时对话、快速查询、简短回复
```

### 深度分析模式
```
模型：GLM-4-Plus
temperature：0.6
top_p：0.9
max_tokens：4000
seed_control：固定

✅ 适用：学术研究、深度报告、复杂推理
```

### 批量生成模式
```
模型：GLM-4.5-Flash
temperature：0.5
top_p：0.85
max_tokens：1500
seed_control：递增

✅ 适用：批量内容生成、系列文章
```

## 📊 参数详解

### Temperature（温度）

| 范围 | 效果 | 适用场景 | 示例 |
|------|------|----------|------|
| 0.1-0.2 | 极度稳定，几乎确定性输出 | 数学计算、代码调试 | "1+1=?" |
| 0.3-0.4 | 非常保守，准确性高 | 技术文档、数据分析 | API文档编写 |
| 0.5-0.6 | 较为稳定，略有变化 | 商业报告、学术写作 | 季度分析报告 |
| 0.7-0.8 | 平衡模式（推荐） | 通用对话、内容创作 | 日常问答 |
| 0.9-1.0 | 创造性强，多样化高 | 文学创作、头脑风暴 | 写小说、想点子 |

### Top-P（核采样）

| 值 | 效果 | 说明 |
|----|------|------|
| 0.7 | 非常保守 | 只从概率最高的70%词汇中选择 |
| 0.8 | 较保守 | 适合专业内容，术语准确 |
| 0.9 | 平衡（推荐） | 通用场景，自然流畅 |
| 0.95 | 词汇丰富 | 创意写作，表达多样 |
| 1.0 | 最大多样性 | 艺术创作，极度创新 |

### Max Tokens（最大令牌数）

| Token数 | 约等于中文字数 | 适用内容 |
|---------|---------------|----------|
| 500 | 150-250字 | 简短回复、摘要 |
| 1000 | 300-500字 | 标准回答、短文 |
| 2000 | 600-1000字 | 详细解答、中等文章 |
| 3000 | 900-1500字 | 深度分析、长文 |
| 4000 | 1200-2000字 | 研究报告、完整文章 |

## 🎯 提示词工程最佳实践

### 1. 结构化输入
```
请按以下结构回答：
## 背景
[问题背景]

## 解决方案
[具体方案]

## 实施步骤
1. ...
2. ...

## 预期效果
[效果说明]
```

### 2. 角色+任务+要求
```
你作为[角色]，需要完成[任务]。
要求：
1. [要求1]
2. [要求2]
3. [要求3]
```

### 3. 示例驱动
```
请按照以下示例的格式生成内容：

示例1：[示例]
示例2：[示例]

现在请为[主题]生成类似内容。
```

### 4. 约束明确
```
请在以下约束下完成任务：
- 字数：500字
- 语言风格：专业但不艰涩
- 避免：技术术语
- 必须包含：3个实例
```

### 5. 思维链引导
```
请逐步思考并解答：
1. 首先，分析问题的核心
2. 然后，列出可能的方案
3. 接着，评估每个方案的优劣
4. 最后，给出推荐方案和理由
```

## 🔬 高级技巧

### 1. 链式提问
```
第一步：请列出解决这个问题的关键步骤
[等待回复]

第二步：请详细说明第2步的具体实现方法
[基于第一步的输出继续]
```

### 2. 角色切换
```
首先，作为程序员分析技术可行性
[回复]

接下来，作为产品经理评估商业价值
[回复]

最后，作为用户体验设计师提出改进建议
[回复]
```

### 3. 批量生成技巧
```
设置：
- seed_control: 递增
- temperature: 0.6

任务：为同一主题生成5个不同角度的文案
执行：运行5次，每次自动使用递增的种子
结果：获得5个相关但不重复的文案
```

### 4. A/B测试
```
设置：
- seed_control: 固定
- seed: 12345

测试：
A方案 (temperature=0.3)
B方案 (temperature=0.8)

对比两个方案的输出差异
```

## ⚠️ 注意事项

1. **种子值范围**：
   - 智谱AI限制：1 - 2,147,483,647
   - 超出范围会自动映射
   - 0表示随机种子

2. **输出长度**：
   - 中文1字 ≈ 2-3 tokens
   - 设置max_tokens时预留余量
   - 输出可能被截断

3. **API成本**：
   - GLM-4-Plus成本最高但能力最强
   - GLM-4.5-Flash性价比最高
   - 合理选择模型控制成本

4. **系统提示词**：
   - 占用token配额
   - 每次请求都会发送
   - 建议控制在200字以内

5. **温度调整**：
   - 创意任务用高温度（0.8-1.0）
   - 准确任务用低温度（0.2-0.4）
   - 通用任务用中等温度（0.6-0.7）

6. **响应时间**：
   - Plus模型相对较慢
   - Flash模型速度最快
   - 长输出耗时更久

7. **内容安全**：
   - 遵守平台使用规范
   - 不生成违规内容
   - 商业使用需授权

## 🔧 配置文件

在 `glm_config.json` 中预设API密钥：

```json
{
    "api_key": "你的智谱AI密钥",
    "model": "GLM-4.5-Flash",
    "timeout": 60
}
```

## 🆚 对比其他模型

### vs 豆包
- **GLM 优势**：中文理解更深，逻辑推理更强
- **豆包优势**：速度更快，成本更低
- **选择建议**：专业/学术用GLM，日常/创意用豆包

### vs GPT系列
- **GLM 优势**：中文原生，文化理解更准
- **GPT 优势**：多语言能力强，训练数据更广
- **选择建议**：中文场景优先GLM

## 📚 相关链接

- [智谱AI开放平台](https://open.bigmodel.cn/)
- [GLM-4 模型文档](https://open.bigmodel.cn/dev/api#glm-4)
- [GLM-4.5 产品介绍](https://open.bigmodel.cn/dev/howuse/model)
- [如何获取API Key](https://open.bigmodel.cn/usercenter/apikeys)
- [提示词工程指南](https://open.bigmodel.cn/dev/howuse/prompts)

---

**作者**：@炮老师的小课堂  
**版本**：v3.1.1  
**更新日期**：2024年

