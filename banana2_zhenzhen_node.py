import torch
import requests
import json
import time
import base64
from PIL import Image
from io import BytesIO
import numpy as np
import comfy.utils
import math

# è¾…åŠ©å‡½æ•°ï¼šTensor è½¬ PIL
def tensor2pil(image):
    return [Image.fromarray(np.clip(255. * img.cpu().numpy().squeeze(), 0, 255).astype(np.uint8)) for img in image]

# è¾…åŠ©å‡½æ•°ï¼šPIL è½¬ Tensor
def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

class DapaoBanana2ZhenzhenNode:
    """
    ğŸ™ˆBanana2è´è´@ç‚®è€å¸ˆçš„å°è¯¾å ‚
    
    æ•´åˆäº† Nano Banana 2 ç”Ÿæˆèƒ½åŠ›ä¸å¤šçº¿è·¯ API åˆ‡æ¢åŠŸèƒ½ã€‚
    æ”¯æŒæ–‡æœ¬ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ï¼ˆå¤šå›¾ç¼–è¾‘ï¼‰ä»¥åŠå¼‚æ­¥ä»»åŠ¡æŸ¥è¯¢ã€‚
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                # API è®¾ç½®éƒ¨åˆ†
                "ğŸŒ APIçº¿è·¯": (["zhenzhen", "ip", "hk", "us"], {"default": "zhenzhen", "tooltip": "é€‰æ‹© API çº¿è·¯ï¼š\nzhenzhen: å›½å†…çº¿è·¯\nhk: é¦™æ¸¯çº¿è·¯\nus: ç¾å›½çº¿è·¯\nip: è‡ªå®šä¹‰åœ°å€"}),
                "ğŸ”‘ APIå¯†é’¥": ("STRING", {"default": "", "multiline": False, "tooltip": "è¯·è¾“å…¥æ‚¨çš„ API Key"}),
                
                # ç”Ÿæˆå‚æ•°éƒ¨åˆ†
                "ğŸ“ æç¤ºè¯": ("STRING", {"multiline": True, "default": "", "tooltip": "æç¤ºè¯"}),
                "ğŸ¨ ç”Ÿæˆæ¨¡å¼": (["æ–‡ç”Ÿå›¾", "å›¾åƒç¼–è¾‘"], {"default": "æ–‡ç”Ÿå›¾", "tooltip": "æ¨¡å¼ï¼šæ–‡ç”Ÿå›¾ æˆ– å›¾åƒç¼–è¾‘"}),
                "ğŸ¤– æ¨¡å‹ç‰ˆæœ¬": (["nano-banana-2", "nano-banana-2-2k", "nano-banana-2-4k"], {"default": "nano-banana-2", "tooltip": "é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬"}),
                "ğŸ“ å®½é«˜æ¯”": (["auto", "16:9", "4:3", "4:5", "3:2", "1:1", "2:3", "3:4", "5:4", "9:16", "21:9"], {"default": "auto", "tooltip": "å®½é«˜æ¯”"}),
                "ğŸ–¼ï¸ å›¾ç‰‡åˆ†è¾¨ç‡": (["1K", "2K", "4K"], {"default": "2K", "tooltip": "å›¾ç‰‡åˆ†è¾¨ç‡"}),
                "ğŸ² éšæœºç§å­": ("INT", {"default": 0, "min": 0, "max": 2147483647, "control_after_generate": "randomize", "tooltip": "éšæœºç§å­"}),
                "ğŸ–¼ï¸ å‡ºå›¾æ•°é‡": ("INT", {"default": 1, "min": 1, "max": 999999, "tooltip": "ä¸€æ¬¡è¯·æ±‚ç”Ÿæˆå›¾ç‰‡æ•°é‡"}),
                "ğŸŒŠ æµå¼è¾“å‡º": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨åé€å¼ æ˜¾ç¤ºç”Ÿæˆç»“æœï¼ˆå¤šå¼ å‡ºå›¾æ—¶æ›´å¿«çœ‹åˆ°ç¬¬ä¸€å¼ ï¼‰"}),
            },
            "optional": {
                # è‡ªå®šä¹‰ API åœ°å€
                "ğŸ”— è‡ªå®šä¹‰APIåœ°å€": ("STRING", {"default": "", "tooltip": "å½“ APIçº¿è·¯ é€‰æ‹© 'ip' æ—¶ï¼Œåœ¨æ­¤è¾“å…¥å®Œæ•´ API åœ°å€ (å¦‚ http://1.2.3.4:8080)"}),
                
                # ä»»åŠ¡æ§åˆ¶
                "ğŸ†” ä»»åŠ¡ID": ("STRING", {"default": "", "tooltip": "å¡«å…¥ä»»åŠ¡ ID å¯æŸ¥è¯¢å†å²ä»»åŠ¡çŠ¶æ€ï¼ˆç•™ç©ºåˆ™åˆ›å»ºæ–°ä»»åŠ¡ï¼‰"}),
                "ğŸ“¦ è¿”å›æ ¼å¼": (["url", "b64_json"], {"default": "url", "tooltip": "è¿”å›æ ¼å¼ï¼šURLé“¾æ¥ æˆ– Base64ç¼–ç "}),
                
                # å¤šå›¾è¾“å…¥ (æ”¯æŒæœ€å¤š14å¼ å›¾)
                "ğŸ–¼ï¸ å‚è€ƒå›¾1": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾2": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾3": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾4": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾5": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾6": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾7": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾8": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾9": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾10": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾11": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾12": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾13": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾14": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("ğŸ–¼ï¸ å›¾åƒ", "ğŸ”— å›¾ç‰‡é“¾æ¥", "ğŸ†” ä»»åŠ¡ID", "â„¹ï¸ å“åº”ä¿¡æ¯")
    FUNCTION = "generate_image"
    CATEGORY = "ğŸ¤–dapaoAPI/Nano Banana 2"

    def __init__(self):
        self.timeout = 600

    def get_headers(self, api_key):
        return {
            "Authorization": f"Bearer {api_key}"
        }

    def _get_base_url(self, api_source, custom_api_url):
        """æ ¹æ®é€‰æ‹©è·å– API Base URL"""
        base_url_mapping = {
            "zhenzhen": "https://ai.t8star.cn",
            "hk": "https://hk-api.gptbest.vip",
            "us": "https://api.gptbest.vip",
            "ip": custom_api_url.strip()
        }
        
        url = base_url_mapping.get(api_source, "")
        if api_source == "ip" and not url:
            print("[dapaoAPI] âš ï¸ è­¦å‘Šï¼šé€‰æ‹©äº† 'ip' æ¨¡å¼ä½†æœªå¡«å†™ 'è‡ªå®šä¹‰APIåœ°å€'ï¼Œå°†é»˜è®¤ä½¿ç”¨ zhenzhen çº¿è·¯")
            return "https://ai.t8star.cn"
            
        return url

    def generate_image(self, **kwargs):
        # 1. å‚æ•°æ˜ å°„ï¼ˆä¸­æ–‡ -> å†…éƒ¨å˜é‡åï¼‰
        api_source = kwargs.get("ğŸŒ APIçº¿è·¯", "zhenzhen")
        api_key = kwargs.get("ğŸ”‘ APIå¯†é’¥", "")
        prompt = kwargs.get("ğŸ“ æç¤ºè¯", "")
        mode_raw = kwargs.get("ğŸ¨ ç”Ÿæˆæ¨¡å¼", "æ–‡ç”Ÿå›¾")
        
        # æ˜ å°„æ¨¡å¼åˆ° API å€¼
        mode_map = {
            "æ–‡ç”Ÿå›¾": "text2img",
            "å›¾åƒç¼–è¾‘": "img2img"
        }
        mode = mode_map.get(mode_raw, "text2img")
        
        model = kwargs.get("ğŸ¤– æ¨¡å‹ç‰ˆæœ¬", "nano-banana-2")
        aspect_ratio = kwargs.get("ğŸ“ å®½é«˜æ¯”", "auto")
        image_size = kwargs.get("ğŸ–¼ï¸ å›¾ç‰‡åˆ†è¾¨ç‡", "2K")
        seed = kwargs.get("ğŸ² éšæœºç§å­", 0)
        n_images_raw = kwargs.get("ğŸ–¼ï¸ å‡ºå›¾æ•°é‡", None)
        if n_images_raw is None:
            n_images_raw = kwargs.get("å‡ºå›¾æ•°é‡", None)
        if n_images_raw is None:
            n_images_raw = 1
        n_images = max(1, int(n_images_raw))
        stream_enabled = bool(kwargs.get("ğŸŒŠ æµå¼è¾“å‡º", False))
        
        custom_api_url = kwargs.get("ğŸ”— è‡ªå®šä¹‰APIåœ°å€", "")
        task_id = kwargs.get("ğŸ†” ä»»åŠ¡ID", "")
        response_format = kwargs.get("ğŸ“¦ è¿”å›æ ¼å¼", "url")
        
        # æå–å›¾ç‰‡
        image1 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾1")
        image2 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾2")
        image3 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾3")
        image4 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾4")
        image5 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾5")
        image6 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾6")
        image7 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾7")
        image8 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾8")
        image9 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾9")
        image10 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾10")
        image11 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾11")
        image12 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾12")
        image13 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾13")
        image14 = kwargs.get("ğŸ–¼ï¸ å‚è€ƒå›¾14")

        # 2. ç¡®å®š API åœ°å€
        base_url = self._get_base_url(api_source, custom_api_url)
        print(f"[dapaoAPI] ä½¿ç”¨ API çº¿è·¯: {api_source} -> {base_url}")
        
        # 3. æ ¡éªŒ API Key
        if not api_key.strip():
            error_message = "âŒ API Key ä¸ºç©ºï¼Œè¯·åœ¨èŠ‚ç‚¹ä¸­å¡«å†™ ğŸ”‘ APIå¯†é’¥"
            print(error_message)
            blank_image = Image.new('RGB', (512, 512), color='black')
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": error_message}))

        try:
            pbar = comfy.utils.ProgressBar(100)
            pbar.update_absolute(10)

            # 4. å¦‚æœæä¾›äº† task_idï¼Œç›´æ¥æŸ¥è¯¢çŠ¶æ€
            if task_id.strip():
                print(f"[dapaoAPI] æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ task_id: {task_id}")
                return self._query_task_status(base_url, api_key, task_id, pbar)
            
            # 5. åˆ›å»ºæ–°ä»»åŠ¡
            print(f"[dapaoAPI] åˆ›å»ºæ–°ä»»åŠ¡ï¼Œæ¨¡å¼: {mode}")

            combined_tensors = []
            all_urls = []
            task_ids = []
            first_url = ""
            first_task_id = ""
            params = {"async": "true"}

            prepared_images = []
            if mode == "img2img":
                all_images = [image1, image2, image3, image4, image5, image6, image7,
                              image8, image9, image10, image11, image12, image13, image14]
                for idx, img in enumerate(all_images):
                    if img is None:
                        continue
                    pil_img = tensor2pil(img)[0]
                    buffered = BytesIO()
                    pil_img.save(buffered, format="PNG")
                    prepared_images.append((f"image_{idx}.png", buffered.getvalue()))
                print(f"[dapaoAPI] å¤„ç† {len(prepared_images)} å¼ è¾“å…¥å›¾ç‰‡")

            for i in range(n_images):
                pbar.update_absolute(min(30, 10 + int((i / max(1, n_images)) * 20)))

                if mode == "text2img":
                    headers = self.get_headers(api_key)
                    headers["Content-Type"] = "application/json"

                    payload = {
                        "prompt": prompt,
                        "model": model,
                        "aspect_ratio": aspect_ratio,
                        "n": 1,
                    }

                    if model == "nano-banana-2":
                        payload["image_size"] = image_size

                    if response_format:
                        payload["response_format"] = response_format

                    if seed > 0:
                        payload["seed"] = seed

                    print(f"[dapaoAPI] å‘é€æ–‡ç”Ÿå›¾è¯·æ±‚: {payload}")
                    response = requests.post(
                        f"{base_url}/v1/images/generations",
                        headers=headers,
                        params=params,
                        json=payload,
                        timeout=self.timeout,
                    )
                else:
                    headers = self.get_headers(api_key)

                    files = []
                    for j, (name, raw) in enumerate(prepared_images):
                        bio = BytesIO(raw)
                        bio.seek(0)
                        files.append(("image", (name, bio, "image/png")))

                    data = {
                        "prompt": prompt,
                        "model": model,
                        "aspect_ratio": aspect_ratio,
                        "n": 1,
                    }

                    if model == "nano-banana-2":
                        data["image_size"] = image_size

                    if response_format:
                        data["response_format"] = response_format

                    if seed > 0:
                        data["seed"] = str(seed)

                    print(f"[dapaoAPI] å‘é€å›¾ç”Ÿå›¾è¯·æ±‚...")
                    response = requests.post(
                        f"{base_url}/v1/images/edits",
                        headers=headers,
                        params=params,
                        data=data,
                        files=files,
                        timeout=self.timeout,
                    )

                if response.status_code != 200:
                    error_message = f"API Error: {response.status_code} - {response.text}"
                    print(error_message)
                    blank_image = Image.new("RGB", (512, 512), color="red")
                    return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": error_message}))

                result = response.json()

                if "task_id" in result:
                    returned_task_id = result["task_id"]
                    task_ids.append(str(returned_task_id))
                    if not first_task_id:
                        first_task_id = str(returned_task_id)
                    img_tensor, img_url, tid, info = self._poll_task(
                        base_url,
                        api_key,
                        returned_task_id,
                        pbar,
                        final_update=not (stream_enabled and n_images > 1),
                    )
                    if isinstance(img_tensor, torch.Tensor) and img_tensor.dim() == 4:
                        combined_tensors.append(img_tensor)
                        if stream_enabled and n_images > 1:
                            preview_tensor = img_tensor[0:1]
                            preview_image = ("PNG", tensor2pil(preview_tensor)[0], None)
                            pbar.update_absolute(
                                min(99, 30 + int(((i + 1) / max(1, n_images)) * 69)),
                                preview=preview_image,
                            )
                    if img_url:
                        if not first_url:
                            first_url = img_url
                        all_urls.append(img_url)
                elif "data" in result and result["data"]:
                    img_tensor, img_url, tid, info = self._process_success_data(result["data"], f"sync_{i}", pbar)
                    if isinstance(img_tensor, torch.Tensor) and img_tensor.dim() == 4:
                        combined_tensors.append(img_tensor)
                        if stream_enabled and n_images > 1:
                            preview_tensor = img_tensor[0:1]
                            preview_image = ("PNG", tensor2pil(preview_tensor)[0], None)
                            pbar.update_absolute(
                                min(99, 30 + int(((i + 1) / max(1, n_images)) * 69)),
                                preview=preview_image,
                            )
                    if img_url:
                        if not first_url:
                            first_url = img_url
                        all_urls.append(img_url)
                else:
                    error_message = f"æœªçŸ¥çš„å“åº”æ ¼å¼: {result}"
                    print(error_message)
                    blank_image = Image.new("RGB", (512, 512), color="gray")
                    return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": error_message}))

            if combined_tensors:
                final_tensor = torch.cat(combined_tensors, dim=0)
                pbar.update_absolute(100)
                return (
                    final_tensor,
                    first_url,
                    first_task_id,
                    json.dumps(
                        {
                            "status": "success",
                            "images_count": int(final_tensor.shape[0]) if isinstance(final_tensor, torch.Tensor) else 0,
                            "image_url": first_url,
                            "all_urls": all_urls,
                            "task_ids": task_ids,
                        },
                        ensure_ascii=False,
                    ),
                )

            blank_image = Image.new("RGB", (512, 512), color="white")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "empty", "message": "No valid images found"}, ensure_ascii=False))
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            error_message = f"ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            print(error_message)
            blank_image = Image.new('RGB', (512, 512), color='red')
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "error", "message": error_message}))

    def _poll_task(self, base_url, api_key, task_id, pbar, final_update=True):
        """è½®è¯¢ä»»åŠ¡çŠ¶æ€"""
        print(f"[dapaoAPI] å¼€å§‹è½®è¯¢ä»»åŠ¡: {task_id}")
        max_attempts = 60  # æœ€å¤šç­‰å¾…10åˆ†é’Ÿ
        attempt = 0
        
        while attempt < max_attempts:
            time.sleep(5)  # æ¯5ç§’æŸ¥è¯¢ä¸€æ¬¡
            attempt += 1
            
            try:
                headers = self.get_headers(api_key)
                headers["Content-Type"] = "application/json"
                
                query_url = f"{base_url}/v1/images/tasks/{task_id}"
                response = requests.get(query_url, headers=headers, timeout=self.timeout)
                
                if response.status_code != 200:
                    print(f"[dapaoAPI] æŸ¥è¯¢å¤±è´¥ ({attempt}): {response.status_code}")
                    continue
                
                result = response.json()
                
                # è§£æçŠ¶æ€
                actual_status = "unknown"
                actual_data = None
                
                if "data" in result and isinstance(result["data"], dict):
                    actual_status = result["data"].get("status", "unknown")
                    actual_data = result["data"].get("data")
                
                print(f"[dapaoAPI] è½®è¯¢ ({attempt}/{max_attempts}) çŠ¶æ€: {actual_status}")
                
                # æˆåŠŸ
                if actual_status in ["completed", "success", "done", "finished", "SUCCESS"]:
                    if final_update:
                        pbar.update_absolute(100)
                    return self._process_success_data(actual_data, task_id, pbar)
                
                # å¤±è´¥
                if actual_status in ["failed", "error", "FAILURE"]:
                    error_msg = result.get("data", {}).get("error", "Unknown error")
                    print(f"[dapaoAPI] ä»»åŠ¡å¤±è´¥: {error_msg}")
                    blank_image = Image.new('RGB', (512, 512), color='red')
                    return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "failed", "message": error_msg}))
                
                # è¿›è¡Œä¸­
                pbar.update_absolute(50 + (attempt % 40))
                
            except Exception as e:
                print(f"[dapaoAPI] è½®è¯¢å¼‚å¸¸: {e}")
        
        print("[dapaoAPI] è½®è¯¢è¶…æ—¶")
        blank_image = Image.new('RGB', (512, 512), color='yellow')
        return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "timeout", "message": "Task polling timed out"}))

    def _query_task_status(self, base_url, api_key, task_id, pbar):
        """å•æ¬¡æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
        return self._poll_task(base_url, api_key, task_id, pbar)

    def _process_success_data(self, data, task_id, pbar):
        """å¤„ç†æˆåŠŸçš„è¿”å›æ•°æ®"""
        generated_tensors = []
        image_urls = []
        
        # å…¼å®¹åˆ—è¡¨æˆ–å•é¡¹
        data_items = data.get("data", []) if isinstance(data, dict) else data
        if not isinstance(data_items, list):
            data_items = [data_items]
            
        for i, item in enumerate(data_items):
            try:
                img_tensor = None
                img_url = ""
                
                if "b64_json" in item and item["b64_json"]:
                    # Base64
                    image_data = base64.b64decode(item["b64_json"])
                    img = Image.open(BytesIO(image_data))
                    if img.mode != 'RGB': img = img.convert('RGB')
                    img_tensor = pil2tensor(img)
                    img_url = "base64_image"
                    
                elif "url" in item and item["url"]:
                    # URL
                    img_url = item["url"]
                    image_urls.append(img_url)
                    # ä¸‹è½½å›¾ç‰‡
                    print(f"[dapaoAPI] ä¸‹è½½å›¾ç‰‡: {img_url}")
                    resp = requests.get(img_url, timeout=self.timeout)
                    resp.raise_for_status()
                    img = Image.open(BytesIO(resp.content))
                    if img.mode != 'RGB': img = img.convert('RGB')
                    img_tensor = pil2tensor(img)
                
                if img_tensor is not None:
                    generated_tensors.append(img_tensor)
                    
            except Exception as e:
                print(f"[dapaoAPI] å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
                continue
        
        if generated_tensors:
            combined_tensor = torch.cat(generated_tensors, dim=0)
            first_url = image_urls[0] if image_urls else ""
            
            result_info = {
                "status": "success",
                "task_id": task_id,
                "images_count": len(generated_tensors),
                "image_url": first_url,
                "all_urls": image_urls
            }
            return (combined_tensor, first_url, task_id, json.dumps(result_info))
        else:
            print("[dapaoAPI] æœªæ‰¾åˆ°æœ‰æ•ˆå›¾ç‰‡æ•°æ®")
            blank_image = Image.new('RGB', (512, 512), color='white')
            return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "empty", "message": "No valid images found"}))


class DapaoBanana2OfficialNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "ğŸ”‘ Google API Key": ("STRING", {"default": "", "multiline": False, "tooltip": "è¯·è¾“å…¥ Google API Key"}),
                "ğŸ“ æç¤ºè¯": ("STRING", {"multiline": True, "default": "", "tooltip": "æç¤ºè¯"}),
                "ğŸ¨ ç”Ÿæˆæ¨¡å¼": (["æ–‡ç”Ÿå›¾", "å›¾åƒç¼–è¾‘"], {"default": "æ–‡ç”Ÿå›¾", "tooltip": "æ¨¡å¼ï¼šæ–‡ç”Ÿå›¾ æˆ– å›¾åƒç¼–è¾‘"}),
                "ğŸ¤– æ¨¡å‹ç‰ˆæœ¬": (["gemini-3-pro-image-preview"], {"default": "gemini-3-pro-image-preview", "tooltip": "é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬"}),
                "ğŸ“ å®½é«˜æ¯”": (["auto", "16:9", "4:3", "4:5", "3:2", "1:1", "2:3", "3:4", "5:4", "9:16", "21:9"], {"default": "auto", "tooltip": "å®½é«˜æ¯”"}),
                "ğŸ–¼ï¸ å›¾ç‰‡åˆ†è¾¨ç‡": (["1K", "2K", "4K"], {"default": "2K", "tooltip": "å›¾ç‰‡åˆ†è¾¨ç‡"}),
                "ğŸ² éšæœºç§å­": ("INT", {"default": 0, "min": 0, "max": 2147483647, "control_after_generate": "randomize", "tooltip": "éšæœºç§å­"}),
                "ğŸ–¼ï¸ å‡ºå›¾æ•°é‡": ("INT", {"default": 1, "min": 1, "max": 999999, "tooltip": "ä¸€æ¬¡è¯·æ±‚ç”Ÿæˆå›¾ç‰‡æ•°é‡"}),
                "ğŸŒŠ æµå¼è¾“å‡º": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨åé€å¼ æ˜¾ç¤ºç”Ÿæˆç»“æœï¼ˆå¤šå¼ å‡ºå›¾æ—¶æ›´å¿«çœ‹åˆ°ç¬¬ä¸€å¼ ï¼‰"}),
            },
            "optional": {
                "ğŸ” å¯ç”¨Googleæœç´¢": ("BOOLEAN", {"default": False, "label_on": "å¯ç”¨æœç´¢å¢å¼º", "label_off": "å…³é—­æœç´¢å¢å¼º"}),
                "ğŸ–¼ï¸ å‚è€ƒå›¾1": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾2": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾3": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾4": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾5": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾6": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾7": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾8": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾9": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾10": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾11": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾12": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾13": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾14": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("ğŸ–¼ï¸ å›¾åƒ", "ğŸ”— å›¾ç‰‡é“¾æ¥", "ğŸ†” ä»»åŠ¡ID", "â„¹ï¸ å“åº”ä¿¡æ¯")
    FUNCTION = "generate_image"
    CATEGORY = "ğŸ¤–dapaoAPI/Nano Banana 2"

    def __init__(self):
        self.timeout = 600

    def _tensor_to_b64(self, img_tensor):
        try:
            pil_img = tensor2pil(img_tensor)[0]
            buffered = BytesIO()
            pil_img.save(buffered, format="PNG")
            return base64.b64encode(buffered.getvalue()).decode("utf-8")
        except Exception:
            return ""

    def _extract_image_bytes(self, resp_json):
        try:
            candidates = resp_json.get("candidates", [])
            for cand in candidates:
                parts = cand.get("content", {}).get("parts", [])
                for part in parts:
                    if part.get("thought", False):
                        continue
                    inline_data = part.get("inlineData") or part.get("inline_data")
                    if not inline_data:
                        continue
                    mime = inline_data.get("mimeType") or inline_data.get("mime_type")
                    if not mime or not str(mime).startswith("image/"):
                        continue
                    b64 = inline_data.get("data")
                    if b64:
                        return base64.b64decode(b64)
        except Exception:
            return None
        return None

    def generate_image(self, **kwargs):
        api_key = kwargs.get("ğŸ”‘ Google API Key", "")
        prompt = kwargs.get("ğŸ“ æç¤ºè¯", "")
        mode_raw = kwargs.get("ğŸ¨ ç”Ÿæˆæ¨¡å¼", "æ–‡ç”Ÿå›¾")
        model = kwargs.get("ğŸ¤– æ¨¡å‹ç‰ˆæœ¬", "gemini-3-pro-image-preview")
        aspect_ratio = kwargs.get("ğŸ“ å®½é«˜æ¯”", "auto")
        image_size = kwargs.get("ğŸ–¼ï¸ å›¾ç‰‡åˆ†è¾¨ç‡", "2K")
        seed = kwargs.get("ğŸ² éšæœºç§å­", 0)
        n_images = max(1, int(kwargs.get("ğŸ–¼ï¸ å‡ºå›¾æ•°é‡", 1) or 1))
        stream_enabled = bool(kwargs.get("ğŸŒŠ æµå¼è¾“å‡º", False))
        enable_google_search = bool(kwargs.get("ğŸ” å¯ç”¨Googleæœç´¢", False))

        mode_map = {"æ–‡ç”Ÿå›¾": "text2img", "å›¾åƒç¼–è¾‘": "img2img"}
        mode = mode_map.get(mode_raw, "text2img")

        if not str(api_key or "").strip():
            error_message = "âŒ Google API Key ä¸ºç©ºï¼Œè¯·åœ¨èŠ‚ç‚¹ä¸­å¡«å†™ ğŸ”‘ Google API Key"
            blank_image = Image.new("RGB", (512, 512), color="black")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": error_message}, ensure_ascii=False))

        input_images = []
        if mode == "img2img":
            for i in range(1, 15):
                img = kwargs.get(f"ğŸ–¼ï¸ å‚è€ƒå›¾{i}")
                if img is not None:
                    input_images.append(img)

        endpoint = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key.strip()}"
        headers = {"Content-Type": "application/json"}

        combined_tensors = []
        pbar = comfy.utils.ProgressBar(100)
        pbar.update_absolute(10)

        try:
            for i in range(n_images):
                pbar.update_absolute(min(30, 10 + int((i / max(1, n_images)) * 20)))

                parts = []
                for img_tensor in input_images:
                    b64 = self._tensor_to_b64(img_tensor)
                    if b64:
                        parts.append({"inlineData": {"mimeType": "image/png", "data": b64}})
                parts.append({"text": prompt})

                payload = {
                    "contents": [{"role": "user", "parts": parts}],
                    "generationConfig": {"responseModalities": ["TEXT", "IMAGE"], "imageConfig": {}},
                }
                if aspect_ratio and str(aspect_ratio).lower() != "auto":
                    payload["generationConfig"]["imageConfig"]["aspectRatio"] = aspect_ratio
                if image_size and str(image_size).lower() != "auto":
                    payload["generationConfig"]["imageConfig"]["imageSize"] = str(image_size).upper()
                if seed and int(seed) > 0:
                    payload["generationConfig"]["seed"] = int(seed)
                if enable_google_search:
                    payload["tools"] = [{"google_search": {}}]

                response = requests.post(endpoint, headers=headers, json=payload, timeout=self.timeout)
                if response.status_code != 200:
                    error_message = f"API Error: {response.status_code} - {response.text}"
                    blank_image = Image.new("RGB", (512, 512), color="red")
                    return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": error_message}, ensure_ascii=False))

                result = response.json()
                img_bytes = self._extract_image_bytes(result)
                if not img_bytes:
                    blank_image = Image.new("RGB", (512, 512), color="gray")
                    return (pil2tensor(blank_image), "", "", json.dumps({"status": "empty", "message": "No image found in response"}, ensure_ascii=False))

                pil_img = Image.open(BytesIO(img_bytes)).convert("RGB")
                img_tensor = pil2tensor(pil_img)
                combined_tensors.append(img_tensor)

                if stream_enabled and n_images > 1:
                    preview_image = ("PNG", pil_img, None)
                    pbar.update_absolute(
                        min(99, 30 + int(((i + 1) / max(1, n_images)) * 69)),
                        preview=preview_image,
                    )

            if combined_tensors:
                final_tensor = torch.cat(combined_tensors, dim=0)
                pbar.update_absolute(100)
                return (
                    final_tensor,
                    "base64_image",
                    "",
                    json.dumps({"status": "success", "images_count": int(final_tensor.shape[0])}, ensure_ascii=False),
                )

            blank_image = Image.new("RGB", (512, 512), color="white")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "empty", "message": "No valid images found"}, ensure_ascii=False))

        except Exception as e:
            import traceback
            traceback.print_exc()
            error_message = f"ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            blank_image = Image.new("RGB", (512, 512), color="red")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "error", "message": error_message}, ensure_ascii=False))


class DapaoCustomBanana2Node:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "ğŸ”‘ APIå¯†é’¥": ("STRING", {"default": "", "multiline": False, "tooltip": "è¯·è¾“å…¥æ‚¨çš„ API Key"}),
                "ğŸŒ APIåœ°å€": ("STRING", {"default": "", "multiline": False, "tooltip": "New API æœåŠ¡åœ°å€ï¼ˆå¡«åŸŸå/ç«¯å£å³å¯ï¼›å¦‚æœä½ ç²˜è´´äº† /v1 æˆ– /v1/images/generations ä¹Ÿä¼šè‡ªåŠ¨çº æ­£ï¼‰"}),
                "ğŸ“ æç¤ºè¯": ("STRING", {"multiline": True, "default": "", "tooltip": "æç¤ºè¯"}),
                "ğŸ¨ ç”Ÿæˆæ¨¡å¼": (["æ–‡ç”Ÿå›¾", "å›¾åƒç¼–è¾‘"], {"default": "æ–‡ç”Ÿå›¾", "tooltip": "æ¨¡å¼ï¼šæ–‡ç”Ÿå›¾ æˆ– å›¾åƒç¼–è¾‘"}),
                "ğŸ¤– æ¨¡å‹ç‰ˆæœ¬": ("STRING", {"default": "nano-banana-2", "multiline": False, "tooltip": "æ¨¡å‹åç§°/IDï¼ˆå¯ç›´æ¥ç²˜è´´ New API é¢æ¿é‡Œçš„æ¨¡å‹åï¼‰"}),
                "ğŸ“ å®½é«˜æ¯”": (["auto", "16:9", "4:3", "4:5", "3:2", "1:1", "2:3", "3:4", "5:4", "9:16", "21:9"], {"default": "auto", "tooltip": "å®½é«˜æ¯”"}),
                "ğŸ–¼ï¸ å›¾ç‰‡åˆ†è¾¨ç‡": (["1K", "2K", "4K"], {"default": "2K", "tooltip": "å›¾ç‰‡åˆ†è¾¨ç‡"}),
                "ğŸ² éšæœºç§å­": ("INT", {"default": 0, "min": 0, "max": 2147483647, "control_after_generate": "randomize", "tooltip": "éšæœºç§å­"}),
                "ğŸ–¼ï¸ å‡ºå›¾æ•°é‡": ("INT", {"default": 1, "min": 1, "max": 999999, "tooltip": "ä¸€æ¬¡è¯·æ±‚ç”Ÿæˆå›¾ç‰‡æ•°é‡"}),
            },
            "optional": {
                "ğŸ†” ä»»åŠ¡ID": ("STRING", {"default": "", "tooltip": "ä»…ç”¨äºé€ä¼ /è®°å½•ï¼›New API Image æ¥å£ä¸€èˆ¬ä¸ºåŒæ­¥è¿”å›"}),
                "ğŸ“¦ è¿”å›æ ¼å¼": (["url", "b64_json"], {"default": "url", "tooltip": "è¿”å›æ ¼å¼ï¼šURLé“¾æ¥ æˆ– Base64ç¼–ç "}),
                "ğŸ–¼ï¸ å‚è€ƒå›¾1": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾2": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾3": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾4": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾5": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾6": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾7": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾8": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾9": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾10": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾11": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾12": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾13": ("IMAGE",),
                "ğŸ–¼ï¸ å‚è€ƒå›¾14": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("ğŸ–¼ï¸ å›¾åƒ", "ğŸ”— å›¾ç‰‡é“¾æ¥", "ğŸ†” ä»»åŠ¡ID", "â„¹ï¸ å“åº”ä¿¡æ¯")
    FUNCTION = "generate_image"
    CATEGORY = "ğŸ¤–dapaoAPI/è®¢åˆ¶API(æµ‹è¯•)"

    def __init__(self):
        self.timeout = 600

    def _normalize_base_url(self, base_url: str) -> str:
        url = str(base_url or "").strip()
        if not url:
            return ""
        url = url.strip("`").strip().strip('"').strip("'")
        url = url.split("?", 1)[0].rstrip("/")

        endpoint_suffixes = [
            "/v1/images/generations",
            "/v1/images/edits",
            "/images/generations",
            "/images/edits",
        ]
        for s in endpoint_suffixes:
            if url.endswith(s):
                url = url[: -len(s)].rstrip("/")
                break

        if url.endswith("/v1"):
            return url
        return f"{url}/v1"

    def _calc_size(self, aspect_ratio: str, image_size: str):
        ratio = (aspect_ratio or "").strip()
        if not ratio or ratio == "auto" or ":" not in ratio:
            return None
        try:
            a, b = ratio.split(":", 1)
            rw = float(a)
            rh = float(b)
            if rw <= 0 or rh <= 0:
                return None
        except Exception:
            return None

        long_side_map = {"1K": 1024}
        long_side = int(long_side_map.get(image_size, 0))
        if long_side <= 0:
            return None

        if rw >= rh:
            w = long_side
            h = int(round(long_side * (rh / rw)))
        else:
            h = long_side
            w = int(round(long_side * (rw / rh)))

        w = max(64, int(math.floor(w / 8) * 8))
        h = max(64, int(math.floor(h / 8) * 8))
        return f"{w}x{h}"

    def _safe_resp_text(self, resp):
        try:
            t = (resp.text or "").strip()
            if t:
                return t
        except Exception:
            pass
        try:
            raw = resp.content
            if raw:
                return raw.decode("utf-8", errors="replace").strip()
        except Exception:
            pass
        return ""

    def _poll_task(self, base_url_v1: str, api_key: str, task_id: str, pbar):
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        max_attempts = 60
        attempt = 0
        while attempt < max_attempts:
            time.sleep(5)
            attempt += 1
            try:
                resp = requests.get(f"{base_url_v1}/images/tasks/{task_id}", headers=headers, timeout=self.timeout)
                if resp.status_code != 200:
                    continue
                result = resp.json()
                data_obj = result.get("data") if isinstance(result, dict) else None
                if not isinstance(data_obj, dict):
                    continue
                status = str(data_obj.get("status", "unknown"))
                payload = data_obj.get("data")
                if status in ["completed", "success", "done", "finished", "SUCCESS"]:
                    pbar.update_absolute(100)
                    return self._process_success_data(payload, task_id, pbar)
                if status in ["failed", "error", "FAILURE"]:
                    blank_image = Image.new("RGB", (512, 512), color="red")
                    return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "failed", "message": data_obj.get("error", "Unknown error"), "raw": result}, ensure_ascii=False))
                pbar.update_absolute(50 + (attempt % 40))
            except Exception:
                continue
        blank_image = Image.new("RGB", (512, 512), color="yellow")
        return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "timeout", "message": "Task polling timed out", "task_id": task_id}, ensure_ascii=False))

    def _process_success_data(self, data, task_id, pbar):
        generated_tensors = []
        image_urls = []

        data_items = data.get("data", []) if isinstance(data, dict) else data
        if not isinstance(data_items, list):
            data_items = [data_items]

        for item in data_items:
            try:
                img_tensor = None
                img_url = ""

                if isinstance(item, dict) and item.get("b64_json"):
                    image_data = base64.b64decode(item["b64_json"])
                    img = Image.open(BytesIO(image_data))
                    if img.mode != "RGB":
                        img = img.convert("RGB")
                    img_tensor = pil2tensor(img)
                    img_url = "base64_image"

                elif isinstance(item, dict) and item.get("url"):
                    img_url = item["url"]
                    image_urls.append(img_url)
                    resp = requests.get(img_url, timeout=self.timeout)
                    resp.raise_for_status()
                    img = Image.open(BytesIO(resp.content))
                    if img.mode != "RGB":
                        img = img.convert("RGB")
                    img_tensor = pil2tensor(img)

                if img_tensor is not None:
                    generated_tensors.append(img_tensor)

            except Exception:
                continue

        if generated_tensors:
            combined_tensor = torch.cat(generated_tensors, dim=0)
            first_url = image_urls[0] if image_urls else ""

            result_info = {
                "status": "success",
                "task_id": task_id,
                "images_count": len(generated_tensors),
                "image_url": first_url,
                "all_urls": image_urls,
            }
            return (combined_tensor, first_url, task_id, json.dumps(result_info, ensure_ascii=False))

        blank_image = Image.new("RGB", (512, 512), color="white")
        return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "empty", "message": "No valid images found"}, ensure_ascii=False))

    def generate_image(self, **kwargs):
        api_key = kwargs.get("ğŸ”‘ APIå¯†é’¥", "")
        api_base = kwargs.get("ğŸŒ APIåœ°å€", "")
        prompt = kwargs.get("ğŸ“ æç¤ºè¯", "")
        mode_raw = kwargs.get("ğŸ¨ ç”Ÿæˆæ¨¡å¼", "æ–‡ç”Ÿå›¾")
        model = str(kwargs.get("ğŸ¤– æ¨¡å‹ç‰ˆæœ¬", "nano-banana-2") or "").strip()
        aspect_ratio = kwargs.get("ğŸ“ å®½é«˜æ¯”", "auto")
        image_size = kwargs.get("ğŸ–¼ï¸ å›¾ç‰‡åˆ†è¾¨ç‡", "2K")
        seed = int(kwargs.get("ğŸ² éšæœºç§å­", 0) or 0)
        n_images = int(kwargs.get("ğŸ–¼ï¸ å‡ºå›¾æ•°é‡", 1) or 1)
        task_id_input = (kwargs.get("ğŸ†” ä»»åŠ¡ID", "") or "").strip()
        response_format = kwargs.get("ğŸ“¦ è¿”å›æ ¼å¼", "url")

        n_images = max(1, int(n_images))

        if not (api_key or "").strip():
            blank_image = Image.new("RGB", (512, 512), color="black")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": "âŒ API Key ä¸ºç©ºï¼Œè¯·åœ¨èŠ‚ç‚¹ä¸­å¡«å†™ ğŸ”‘ APIå¯†é’¥"}, ensure_ascii=False))

        base_url_v1 = self._normalize_base_url(api_base)
        if not base_url_v1:
            blank_image = Image.new("RGB", (512, 512), color="black")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": "âŒ APIåœ°å€ ä¸ºç©ºï¼Œè¯·å¡«å†™ ğŸŒ APIåœ°å€"}, ensure_ascii=False))

        images = [kwargs.get(f"ğŸ–¼ï¸ å‚è€ƒå›¾{i}") for i in range(1, 15)]
        has_any_image = any(img is not None for img in images)

        pbar = comfy.utils.ProgressBar(100)
        pbar.update_absolute(10)

        size_str = self._calc_size(aspect_ratio, image_size)

        try:
            headers = {"Authorization": f"Bearer {api_key}"}
            params = {"async": "true"}

            if mode_raw == "å›¾åƒç¼–è¾‘":
                if not has_any_image:
                    blank_image = Image.new("RGB", (512, 512), color="black")
                    return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": "âŒ å›¾åƒç¼–è¾‘æ¨¡å¼è‡³å°‘éœ€è¦ 1 å¼ å‚è€ƒå›¾"}, ensure_ascii=False))

                files = []
                image_count = 0
                for img in images:
                    if img is None:
                        continue
                    pil_img = tensor2pil(img)[0]
                    buffered = BytesIO()
                    pil_img.save(buffered, format="PNG")
                    buffered.seek(0)
                    files.append(("image", (f"image_{image_count}.png", buffered, "image/png")))
                    image_count += 1

                data = {
                    "prompt": prompt,
                    "model": model,
                    "n": n_images,
                    "response_format": response_format,
                }
                if size_str:
                    data["size"] = size_str
                if seed > 0:
                    data["seed"] = str(seed)
                if task_id_input:
                    data["task_id"] = task_id_input

                resp = requests.post(
                    f"{base_url_v1}/images/edits",
                    headers=headers,
                    params=params,
                    data=data,
                    files=files,
                    timeout=self.timeout,
                )
            else:
                headers["Content-Type"] = "application/json"
                payload = {
                    "model": model,
                    "prompt": prompt,
                    "n": n_images,
                    "response_format": response_format,
                }
                if size_str:
                    payload["size"] = size_str
                if seed > 0:
                    payload["seed"] = seed
                if task_id_input:
                    payload["task_id"] = task_id_input

                resp = requests.post(
                    f"{base_url_v1}/images/generations",
                    headers=headers,
                    params=params,
                    json=payload,
                    timeout=self.timeout,
                )

            pbar.update_absolute(40)

            if resp.status_code != 200:
                blank_image = Image.new("RGB", (512, 512), color="red")
                return (pil2tensor(blank_image), "", "", json.dumps({"status": "failed", "message": f"API Error: {resp.status_code} - {self._safe_resp_text(resp)}", "endpoint": str(resp.url)}, ensure_ascii=False))

            result = resp.json()
            task_id = str(result.get("task_id") or result.get("id") or task_id_input or "")
            data = result.get("data")
            if not data and isinstance(result, dict) and result.get("task_id"):
                pbar.update_absolute(50)
                return self._poll_task(base_url_v1, api_key, task_id, pbar)
            if not data:
                blank_image = Image.new("RGB", (512, 512), color="gray")
                return (pil2tensor(blank_image), "", task_id, json.dumps({"status": "failed", "message": "æœªåœ¨å“åº”ä¸­æ‰¾åˆ° data", "raw": result}, ensure_ascii=False))

            pbar.update_absolute(80)
            return self._process_success_data(data, task_id, pbar)
        except Exception as e:
            blank_image = Image.new("RGB", (512, 512), color="red")
            return (pil2tensor(blank_image), "", "", json.dumps({"status": "error", "message": str(e)}, ensure_ascii=False))
